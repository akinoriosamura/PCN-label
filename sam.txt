Epoch:[70  ][350 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][360 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][370 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][380 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][390 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][400 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][410 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][420 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][430 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][440 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][450 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][460 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][470 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][480 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][490 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][500 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][510 /585 ]	Loss 0.046	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][520 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][530 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][540 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][550 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][560 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][570 /585 ]	Loss 0.071	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][580 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[70  ][585 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
train time: 282.1441285610199
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[71  ][10  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][20  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][30  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][40  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][50  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][60  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][70  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][80  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][90  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][100 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][110 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][120 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][130 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][140 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][150 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][160 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][170 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][180 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][190 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][200 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][210 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][220 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][230 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][240 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][250 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][260 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][270 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][280 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][290 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][300 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][310 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][320 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][330 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][340 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][350 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][360 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][370 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][380 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][390 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][400 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][410 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][420 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][430 /585 ]	Loss 0.069	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][440 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][450 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][460 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][470 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][480 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][490 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][500 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][510 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][520 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][530 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][540 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][550 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][560 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][570 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][580 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[71  ][585 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
train time: 277.4269196987152
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[72  ][10  /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][20  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][30  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][40  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][50  /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][60  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][70  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][80  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][90  /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][100 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][110 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][120 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][130 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][140 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][150 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][160 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][170 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][180 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][190 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][200 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][210 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][220 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][230 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][240 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][250 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][260 /585 ]	Loss 0.070	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][270 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][280 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][290 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][300 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][310 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][320 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][330 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][340 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][350 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][360 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][370 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][380 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][390 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][400 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][410 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][420 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][430 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][440 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][450 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][460 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][470 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][480 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][490 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][500 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][510 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][520 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][530 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][540 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][550 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][560 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][570 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][580 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[72  ][585 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
train time: 277.567485332489
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[73  ][10  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][20  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][30  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][40  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][50  /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][60  /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][70  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][80  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][90  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][100 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][110 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][120 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][130 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][140 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][150 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][160 /585 ]	Loss 0.070	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][170 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][180 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][190 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][200 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][210 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][220 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][230 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][240 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][250 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][260 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][270 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][280 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][290 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][300 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][310 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][320 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][330 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][340 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][350 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][360 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][370 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][380 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][390 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][400 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][410 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][420 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][430 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][440 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][450 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][460 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][470 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][480 /585 ]	Loss 0.075	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][490 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][500 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][510 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][520 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][530 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][540 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][550 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][560 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][570 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][580 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[73  ][585 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
train time: 277.3599646091461
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[74  ][10  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][20  /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][30  /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][40  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][50  /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][60  /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][70  /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][80  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][90  /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][100 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][110 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][120 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][130 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][140 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][150 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][160 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][170 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][180 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][190 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][200 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][210 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][220 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][230 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][240 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][250 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][260 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][270 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][280 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][290 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][300 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][310 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][320 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][330 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][340 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][350 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][360 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][370 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][380 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][390 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][400 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][410 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][420 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][430 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][440 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][450 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][460 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][470 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][480 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][490 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][500 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][510 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][520 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][530 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][540 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][550 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][560 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][570 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][580 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[74  ][585 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
train time: 277.1495907306671
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
============ get train data ===============
======= not augment =========
save in record dataset :  ./data/unaugment_train.tfrecords
============ get test data ===============
======= not augment =========
save in record dataset :  ./data/unaugment_test.tfrecords
Total number of examples: 75000
Test number of examples: 2500
train start
Epoch:[75  ][10  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][20  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][30  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][40  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][50  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][60  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][70  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][80  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][90  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][100 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][110 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][120 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][130 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][140 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][150 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][160 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][170 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][180 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][190 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][200 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][210 /585 ]	Loss 0.070	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][220 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][230 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][240 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][250 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][260 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][270 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][280 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][290 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][300 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][310 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][320 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][330 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][340 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][350 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][360 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][370 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][380 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][390 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][400 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][410 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][420 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][430 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][440 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][450 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][460 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][470 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][480 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][490 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][500 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][510 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][520 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][530 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][540 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][550 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][560 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][570 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][580 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[75  ][585 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
train time: 277.71250343322754
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[76  ][10  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][20  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][30  /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][40  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][50  /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][60  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][70  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][80  /585 ]	Loss 0.073	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][90  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][100 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][110 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][120 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][130 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][140 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][150 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][160 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][170 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][180 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][190 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][200 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][210 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][220 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][230 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][240 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][250 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][260 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][270 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][280 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][290 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][300 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][310 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][320 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][330 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][340 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][350 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][360 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][370 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][380 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][390 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][400 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][410 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][420 /585 ]	Loss 0.073	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][430 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][440 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][450 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][460 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][470 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][480 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][490 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][500 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][510 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][520 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][530 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][540 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][550 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][560 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][570 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][580 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[76  ][585 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
train time: 277.8210380077362
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[77  ][10  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][20  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][30  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][40  /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][50  /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][60  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][70  /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][80  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][90  /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][100 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][110 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][120 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][130 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][140 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][150 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][160 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][170 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][180 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][190 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][200 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][210 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][220 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][230 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][240 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][250 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][260 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][270 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][280 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][290 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][300 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][310 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][320 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][330 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][340 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][350 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][360 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][370 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][380 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][390 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][400 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][410 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][420 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][430 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][440 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][450 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][460 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][470 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][480 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][490 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][500 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][510 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][520 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][530 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][540 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][550 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][560 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][570 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][580 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[77  ][585 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
train time: 277.33985662460327
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[78  ][10  /585 ]	Loss 0.071	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][20  /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][30  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][40  /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][50  /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][60  /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][70  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][80  /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][90  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][100 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][110 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][120 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][130 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][140 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][150 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][160 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][170 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][180 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][190 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][200 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][210 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][220 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][230 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][240 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][250 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][260 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][270 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][280 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][290 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][300 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][310 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][320 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][330 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][340 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][350 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][360 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][370 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][380 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][390 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][400 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][410 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][420 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][430 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][440 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][450 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][460 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][470 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][480 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][490 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][500 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][510 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][520 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][530 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][540 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][550 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][560 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][570 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][580 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[78  ][585 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
train time: 277.4640669822693
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[79  ][10  /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][20  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][30  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][40  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][50  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][60  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][70  /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][80  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][90  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][100 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][110 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][120 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][130 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][140 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][150 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][160 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][170 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][180 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][190 /585 ]	Loss 0.074	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][200 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][210 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][220 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][230 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][240 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][250 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][260 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][270 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][280 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][290 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][300 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][310 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][320 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][330 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][340 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][350 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][360 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][370 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][380 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][390 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][400 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][410 /585 ]	Loss 0.085	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][420 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][430 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][440 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][450 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][460 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][470 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][480 /585 ]	Loss 0.071	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][490 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][500 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][510 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][520 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][530 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][540 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][550 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][560 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][570 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][580 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[79  ][585 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
train time: 281.8889374732971
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
============ get train data ===============
======= not augment =========
save in record dataset :  ./data/unaugment_train.tfrecords
============ get test data ===============
======= not augment =========
save in record dataset :  ./data/unaugment_test.tfrecords
Total number of examples: 75000
Test number of examples: 2500
train start
Epoch:[80  ][10  /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][20  /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][30  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][40  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][50  /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][60  /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][70  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][80  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][90  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][100 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][110 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][120 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][130 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][140 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][150 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][160 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][170 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][180 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][190 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][200 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][210 /585 ]	Loss 0.070	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][220 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][230 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][240 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][250 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][260 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][270 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][280 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][290 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][300 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][310 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][320 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][330 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][340 /585 ]	Loss 0.070	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][350 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][360 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][370 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][380 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][390 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][400 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][410 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][420 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][430 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][440 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][450 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][460 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][470 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][480 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][490 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][500 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][510 /585 ]	Loss 0.046	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][520 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][530 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][540 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][550 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][560 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][570 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][580 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[80  ][585 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
train time: 282.2317099571228
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
test start
num test file:  2500
test epoch size:  20
start epoch:  0
start epoch:  1
start epoch:  2
start epoch:  3
start epoch:  4
start epoch:  5
start epoch:  6
start epoch:  7
start epoch:  8
start epoch:  9
start epoch:  10
start epoch:  11
start epoch:  12
start epoch:  13
start epoch:  14
start epoch:  15
start epoch:  16
start epoch:  17
start epoch:  18
start epoch:  19
Test epochs: 20	Loss 0.090
mean error and failure rate
mean error : 0.063
failure rate: L1 0.996

test time: 7511.878545999527
train start
Epoch:[81  ][10  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][20  /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][30  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][40  /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][50  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][60  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][70  /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][80  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][90  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][100 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][110 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][120 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][130 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][140 /585 ]	Loss 0.045	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][150 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][160 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][170 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][180 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][190 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][200 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][210 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][220 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][230 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][240 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][250 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][260 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][270 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][280 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][290 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][300 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][310 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][320 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][330 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][340 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][350 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][360 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][370 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][380 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][390 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][400 /585 ]	Loss 0.072	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][410 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][420 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][430 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][440 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][450 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][460 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][470 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][480 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][490 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][500 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][510 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][520 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][530 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][540 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][550 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][560 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][570 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][580 /585 ]	Loss 0.044	L2_loss 0.003	 lr 1e-08
Epoch:[81  ][585 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
train time: 281.6142563819885
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[82  ][10  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][20  /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][30  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][40  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][50  /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][60  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][70  /585 ]	Loss 0.069	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][80  /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][90  /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][100 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][110 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][120 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][130 /585 ]	Loss 0.069	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][140 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][150 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][160 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][170 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][180 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][190 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][200 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][210 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][220 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][230 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][240 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][250 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][260 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][270 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][280 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][290 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][300 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][310 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][320 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][330 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][340 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][350 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][360 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][370 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][380 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][390 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][400 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][410 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][420 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][430 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][440 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][450 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][460 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][470 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][480 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][490 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][500 /585 ]	Loss 0.046	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][510 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][520 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][530 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][540 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][550 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][560 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][570 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][580 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[82  ][585 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
train time: 277.42131662368774
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[83  ][10  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][20  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][30  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][40  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][50  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][60  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][70  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][80  /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][90  /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][100 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][110 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][120 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][130 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][140 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][150 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][160 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][170 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][180 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][190 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][200 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][210 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][220 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][230 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][240 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][250 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][260 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][270 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][280 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][290 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][300 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][310 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][320 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][330 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][340 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][350 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][360 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][370 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][380 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][390 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][400 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][410 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][420 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][430 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][440 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][450 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][460 /585 ]	Loss 0.073	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][470 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][480 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][490 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][500 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][510 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][520 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][530 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][540 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][550 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][560 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][570 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][580 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[83  ][585 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
train time: 277.3651740550995
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[84  ][10  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][20  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][30  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][40  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][50  /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][60  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][70  /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][80  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][90  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][100 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][110 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][120 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][130 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][140 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][150 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][160 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][170 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][180 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][190 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][200 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][210 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][220 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][230 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][240 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][250 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][260 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][270 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][280 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][290 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][300 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][310 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][320 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][330 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][340 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][350 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][360 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][370 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][380 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][390 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][400 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][410 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][420 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][430 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][440 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][450 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][460 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][470 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][480 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][490 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][500 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][510 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][520 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][530 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][540 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][550 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][560 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][570 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][580 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[84  ][585 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
train time: 277.5162453651428
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
============ get train data ===============
======= not augment =========
save in record dataset :  ./data/unaugment_train.tfrecords
============ get test data ===============
======= not augment =========
save in record dataset :  ./data/unaugment_test.tfrecords
Total number of examples: 75000
Test number of examples: 2500
train start
Epoch:[85  ][10  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][20  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][30  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][40  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][50  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][60  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][70  /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][80  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][90  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][100 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][110 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][120 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][130 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][140 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][150 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][160 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][170 /585 ]	Loss 0.074	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][180 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][190 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][200 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][210 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][220 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][230 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][240 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][250 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][260 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][270 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][280 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][290 /585 ]	Loss 0.079	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][300 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][310 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][320 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][330 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][340 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][350 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][360 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][370 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][380 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][390 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][400 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][410 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][420 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][430 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][440 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][450 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][460 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][470 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][480 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][490 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][500 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][510 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][520 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][530 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][540 /585 ]	Loss 0.045	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][550 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][560 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][570 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][580 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[85  ][585 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
train time: 278.118346452713
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[86  ][10  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][20  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][30  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][40  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][50  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][60  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][70  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][80  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][90  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][100 /585 ]	Loss 0.069	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][110 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][120 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][130 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][140 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][150 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][160 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][170 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][180 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][190 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][200 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][210 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][220 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][230 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][240 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][250 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][260 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][270 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][280 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][290 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][300 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][310 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][320 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][330 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][340 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][350 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][360 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][370 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][380 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][390 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][400 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][410 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][420 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][430 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][440 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][450 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][460 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][470 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][480 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][490 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][500 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][510 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][520 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][530 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][540 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][550 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][560 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][570 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][580 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[86  ][585 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
train time: 282.1291284561157
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[87  ][10  /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][20  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][30  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][40  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][50  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][60  /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][70  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][80  /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][90  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][100 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][110 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][120 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][130 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][140 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][150 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][160 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][170 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][180 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][190 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][200 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][210 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][220 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][230 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][240 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][250 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][260 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][270 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][280 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][290 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][300 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][310 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][320 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][330 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][340 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][350 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][360 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][370 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][380 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][390 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][400 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][410 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][420 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][430 /585 ]	Loss 0.067	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][440 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][450 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][460 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][470 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][480 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][490 /585 ]	Loss 0.070	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][500 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][510 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][520 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][530 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][540 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][550 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][560 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][570 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][580 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[87  ][585 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
train time: 281.6427662372589
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[88  ][10  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][20  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][30  /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][40  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][50  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][60  /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][70  /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][80  /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][90  /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][100 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][110 /585 ]	Loss 0.073	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][120 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][130 /585 ]	Loss 0.073	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][140 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][150 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][160 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][170 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][180 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][190 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][200 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][210 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][220 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][230 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][240 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][250 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][260 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][270 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][280 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][290 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][300 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][310 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][320 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][330 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][340 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][350 /585 ]	Loss 0.071	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][360 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][370 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][380 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][390 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][400 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][410 /585 ]	Loss 0.047	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][420 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][430 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][440 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][450 /585 ]	Loss 0.066	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][460 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][470 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][480 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][490 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][500 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][510 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][520 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][530 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][540 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][550 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][560 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][570 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][580 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[88  ][585 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
train time: 281.7783257961273
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
train start
Epoch:[89  ][10  /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][20  /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][30  /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][40  /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][50  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][60  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][70  /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][80  /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][90  /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][100 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][110 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][120 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][130 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][140 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][150 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][160 /585 ]	Loss 0.063	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][170 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][180 /585 ]	Loss 0.075	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][190 /585 ]	Loss 0.076	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][200 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][210 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][220 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][230 /585 ]	Loss 0.062	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][240 /585 ]	Loss 0.064	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][250 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][260 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][270 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][280 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][290 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][300 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][310 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][320 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][330 /585 ]	Loss 0.068	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][340 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][350 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][360 /585 ]	Loss 0.055	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][370 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][380 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][390 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][400 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][410 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][420 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][430 /585 ]	Loss 0.053	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][440 /585 ]	Loss 0.051	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][450 /585 ]	Loss 0.057	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][460 /585 ]	Loss 0.058	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][470 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][480 /585 ]	Loss 0.052	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][490 /585 ]	Loss 0.059	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][500 /585 ]	Loss 0.050	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][510 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][520 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][530 /585 ]	Loss 0.054	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][540 /585 ]	Loss 0.061	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][550 /585 ]	Loss 0.048	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][560 /585 ]	Loss 0.049	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][570 /585 ]	Loss 0.056	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][580 /585 ]	Loss 0.065	L2_loss 0.003	 lr 1e-08
Epoch:[89  ][585 /585 ]	Loss 0.060	L2_loss 0.003	 lr 1e-08
train time: 281.53916931152344
save checkpoint: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt
============ get train data ===============
======= not augment =========
^CTraceback (most recent call last):
  File "train_model.py", line 449, in <module>
    main(parse_arguments(sys.argv[1:]))
  File "train_model.py", line 179, in main
    _, train_dataset = train_loader.gen_tfrecord()
  File "/usr/src/app/generate_data.py", line 112, in gen_tfrecord
    self.write_tfrecord(tfrecord_path)
  File "/usr/src/app/generate_data.py", line 68, in write_tfrecord
    ex = self.make_example(image, landmark, attribute, euler_angle)
  File "/usr/src/app/generate_data.py", line 62, in make_example
    'euler_angle' : tf.train.Feature(float_list=tf.train.FloatList(value=euler_angle.reshape(-1)))
KeyboardInterrupt

]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# l
Dockerfile                          requirement.txt
Pipfile                             run.sh
Pipfile.lock                        [0m[01;34ms_augim112[0m/
README.md                           [01;34ms_im112[0m/
[01;34m__pycache__[0m/                        [01;34ms_im56_moru_dataset_preWFLW68[0m/
[01;34maug_sample_result[0m/                  [01;34msa_PFLD_growing_68_pre_WFLW[0m/
camera.py                           [01;34msa_im56_PFLE_WFLW68[0m/
convert_savedmodel_keras_tflite.py  [01;34msa_im56_moru_cleaned_preWFLW_68[0m/
convert_tflite.py                   [01;34msample_aug[0m/
[01;34mdata[0m/                               [01;34msample_aug_WFLW68_ignore_attribute[0m/
data_augmentor.py                   [01;34msample_dm05_morucleaned_preWFLW[0m/
[34;42mdocker[0m/                             [01;34msample_dm05_morucleanedv2_premoruclean[0m/
docker-compose.yml                  [01;34msample_new_dm05_WFLW68[0m/
euler_angles.py                     save.sh
euler_angles_utils.py               save_model.py
generate_data.py                    [34;42mtensorboard[0m/
[01;32mmb_keras.py[0m*                        test_model.py
[34;42mmodels2[0m/                            test_pb.py
[34;42mmtcnn[0m/                              [34;42mtools[0m/
pfld.py                             train.sh
[01;32mpfld.pyc[0m*                           train_model.py
[01;32mpfld_mbv3.py[0m*                       train_model_new.py
[01;32mpfld_mbv3_keras.py[0m*                 utils.py
pfld_new.py                         [01;32mutils.pyc[0m*
]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# s[Kls
Dockerfile                          requirement.txt
Pipfile                             run.sh
Pipfile.lock                        [0m[01;34ms_augim112[0m
README.md                           [01;34ms_im112[0m
[01;34m__pycache__[0m                         [01;34ms_im56_moru_dataset_preWFLW68[0m
[01;34maug_sample_result[0m                   [01;34msa_PFLD_growing_68_pre_WFLW[0m
camera.py                           [01;34msa_im56_PFLE_WFLW68[0m
convert_savedmodel_keras_tflite.py  [01;34msa_im56_moru_cleaned_preWFLW_68[0m
convert_tflite.py                   [01;34msample_aug[0m
[01;34mdata[0m                                [01;34msample_aug_WFLW68_ignore_attribute[0m
data_augmentor.py                   [01;34msample_dm05_morucleaned_preWFLW[0m
[34;42mdocker[0m                              [01;34msample_dm05_morucleanedv2_premoruclean[0m
docker-compose.yml                  [01;34msample_new_dm05_WFLW68[0m
euler_angles.py                     save.sh
euler_angles_utils.py               save_model.py
generate_data.py                    [34;42mtensorboard[0m
[01;32mmb_keras.py[0m                         test_model.py
[34;42mmodels2[0m                             test_pb.py
[34;42mmtcnn[0m                               [34;42mtools[0m
pfld.py                             train.sh
[01;32mpfld.pyc[0m                            train_model.py
[01;32mpfld_mbv3.py[0m                        train_model_new.py
[01;32mpfld_mbv3_keras.py[0m                  utils.py
pfld_new.py                         [01;32mutils.pyc[0m
]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# vim run.sh 
[?2004h[?1049h[22;0;0t[?1h=[?2004h[1;13r[?12h[?12l[27m[23m[29m[m[H[2J[?25l[13;1H"run.sh" 93L, 4198C[2;1H▽[6n[2;1H  [1;1H[>c]10;?]11;?[1;1H[36mphase[m=[35m$1[m
[36mnum_labels[m=[31m68[m
[36mdepth_multi[m=[31m0[m.[31m75[m [34m# default = 1, like model complicated[m
[36mnum_quant[m=[31m64[m
[36msave_model[m=models2/save_models/[31m68[m/new_dm075_im84_WFLW68
[36mfile_list[m=data/rotated_train_WFLW_68_data/list.txt
[36mtest_list[m=data/rotated_test_WFLW_68_data/list.txt
[34m# test_list=data/test_moru_dataset/list.txt[m
[36mpre_model[m=models2/save_models/[31m68[m/new_dm075_im84_WFLW68
[36mout_dir[m=sample_new_dm05_WFLW68
[36mlr[m=[31m0[m.[31m0001[m
[36mis_augment[m=False  [34m# True or False[m[13;84H8,36[11C1%[7;36H[?25h[?12$p[?25l[13;74Hi[7;36H[13;74H [7;36H[13;1H[1m-- INSERT --[m[13;13H[K[13;84H8,36[11C1%[7;36H[?25h[?25l[13;87H5[7;35H[?25h[?25l[13;87H4[7;34H[?25h[?25l[13;87H3[7;33H[?25h[?25l[13;87H2[7;32H[?25h[?25l[13;87H1[7;31H[?25h[?25l[13;87H0[7;30H[?25h[?25l[13;86H29[7;29H[?25h[?25l[13;87H8[7;28H[?25h[?25l[13;87H7[7;27H[?25h[?25l[13;87H6[7;26H[?25h[?25l[13;87H5[7;25H[?25h[?25l[13;87H4[7;24H[?25h[?25l[13;87H3[7;23H[?25h[?25l[13;87H2[7;22H[?25h[?25l[13;87H1[7;21H[?25h[?25l[13;87H0[7;20H[?25h[?25l[13;86H19[7;19H[?25h[?25l[13;87H8[7;18H[?25h[?25l[13;87H7[7;17H[?25h[?25l[13;87H6[7;16H[?25h[?25l[13;87H5[7;15H[?25h[?25l[13;87H4[7;14H[?25h[?25l[13;87H3[7;13H[?25h[?25l[13;87H2[7;12H[?25h[?25l[13;87H1[7;11H[?25h[?25l[13;87H0[7;10H[?25h[?25l[13;86H9 [7;9H[?25h[?25l[13;86H8[7;8H[?25h[?25l[13;86H7[7;7H[?25h[?25l[13;86H6[7;6H[?25h[?25l[13;86H5[7;5H[?25h[?25l[13;86H4[7;4H[?25h[?25l[13;86H3[7;3H[?25h[?25l[13;86H2[7;2H[?25h[?25l[13;86H1[7;1H[?25h[?25l[34m#test_list=data/rotated_test_WFLW_68_data/list.txt[m[13;86H2[7;2H[?25h[?25l[34m test_list=data/rotated_test_WFLW_68_data/list.txt[m[13;86H3[7;3H[?25h[?25l[1;12r[12;1H
[1;13r[12;1H[36mimage_size[m=[31m84[m[13;84H[K[13;84H9,3[12C2%[7;3H[?25h[?25l[34mtest_list=data/test_moru_dataset/list.txt[m[7;43H[K[13;86H2[7;2H[?25h[?25l[36mtest_list[m=data/test_moru_dataset/list.txt[7;42H[K[13;86H1[7;1H[?25h[?25l[1;12r[12;1H
[1;13r[13;84H[K[13;84H10,1[11C3%[7;1H[?25h[?25l[1;12r[12;1H
[1;13r[12;1H[34m# --pretrained_model=${pre_model} \[m[13;84H[K[13;84H11,1[11C4%[7;1H[?25h[?25l[13;87H2[7;2H[?25h[?25l[13;87H3[7;3H[?25h[?25l[13;87H4[7;4H[?25h[?25l[13;87H5[7;5H[?25h[?25l[13;87H6[7;6H[?25h[?25l[13;87H7[7;7H[?25h[?25l[13;87H8[7;8H[?25h[?25l[13;87H9[7;9H[?25h[?25l[13;87H10[7;10H[?25h[?25l[13;88H1[7;11H[?25h[?25l[13;88H2[7;12H[?25h[?25l[13;88H3[7;13H[?25h[?25l[13;88H4[7;14H[?25h[?25l[13;88H5[7;15H[?25h[?25l[13;88H6[7;16H[?25h[?25l[13;88H7[7;17H[?25h[?25l[13;88H8[7;18H[?25h[?25l[13;88H9[7;19H[?25h[?25l[13;87H20[7;20H[?25h[?25l[13;88H1[7;21H[?25h[?25l[13;88H2[7;22H[?25h[?25l[13;88H3[7;23H[?25h[?25l[13;88H4[7;24H[?25h[?25l[13;88H5[7;25H[?25h[?25l[13;88H6[7;26H[?25h[?25l[13;88H7[7;27H[?25h[?25l[13;88H8[7;28H[?25h[?25l[13;88H9[7;29H[?25h[?25l[13;87H30[7;30H[?25h[?25l[13;88H1[7;31H[?25h[?25l[7;30H[K[13;88H0[7;30H[?25h[?25l[7;29H[K[13;87H29[7;29H[?25h[?25l[7;28H[K[13;88H8[7;28H[?25h[?25l[7;27H[K[13;88H7[7;27H[?25h[?25l[7;26H[K[13;88H6[7;26H[?25h[?25l[7;25H[K[13;88H5[7;25H[?25h[?25l[7;24H[K[13;88H4[7;24H[?25h[?25l[7;23H[K[13;88H3[7;23H[?25h[?25l[7;22H[K[13;88H2[7;22H[?25h[?25l[7;21H[K[13;88H1[7;21H[?25h[?25l[7;20H[K[13;88H0[7;20H[?25h[?25l[7;19H[K[13;87H19[7;19H[?25h[?25l[7;18H[K[13;88H8[7;18H[?25h[?25l[7;17H[K[13;88H7[7;17H[?25h[?25l[7;16H[K[13;88H6[7;16H[?25h[?25lnew_dm075_im84_WFLW68[13;87H37[7;37H[?25h[?25l[13;85H0[6;37H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[36mdepth_multi[m=[31m0[m.[31m75[m [34m# default = 1, like model complicated[m[13;84H[K[13;84H9,37[11C3%[6;37H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[36mnum_labels[m=[31m68[m[13;84H[K[13;84H8,37[11C2%[6;37H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[36mphase[m=[35m$1[m[13;84H[K[13;84H7,37[11C1%[6;37H[?25h[13;1H[K[6;36H[?25l[13;74H^[[6;36H[13;74H  [6;37H[13;84H7,36[11C1%[6;36H[?25h[?25l[13;74H:[6;36H[13;74H[K[13;1H:[?2004h[?25hw[?25l[?25hq[?25l[?25h[?25l[?2004l"run.sh" 93L, 4204C written
[?2004l[?1l>[?25h[?1049l[23;0;0t]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# sh run.sh save
run save
['save_model.py', '--model_dir=models2/save_models/68/new_dm075_im84_WFLW68', '--pretrained_model=models2/save_models/68/new_dm075_im84_WFLW68', '--test_list=data/test_moru_dataset/list.txt', '--num_labels=68', '--learning_rate=0.0001', '--level=L1', '--image_size=84', '--batch_size=128', '--depth_multi=0.75', '--num_quant=64', '--is_augment=False']
WARNING: Logging before flag parsing goes to stderr.
W0207 06:12:43.243064 139737673410368 deprecation_wrapper.py:119] From save_model.py:84: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0207 06:12:43.245633 139737673410368 deprecation_wrapper.py:119] From /usr/src/app/pfld.py:179: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

labels;  68
labels;  68
W0207 06:12:49.252235 139737673410368 deprecation_wrapper.py:119] From /usr/src/app/pfld.py:77: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

PFLD input shape(image_batch:0): (?, 84, 84, 3)
pfld_inference/conv1/Relu6:0 (?, 42, 42, 48)
W0207 06:12:49.463020 139737673410368 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
pfld_inference/conv2/dwise/Relu6:0 (?, 42, 42, 48)
pfld_inference/conv3_1/inbottleneck/conv2d_1/Relu6:0 (?, 42, 42, 96)
pfld_inference/conv3_1/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_2/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_2/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_2/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_3/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_3/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_3/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_4/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_4/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_4/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_5/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_5/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_5/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv4/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv4/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 96)
pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_1/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_1/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_1/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_2/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_2/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_2/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_3/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_3/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_3/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_4/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_4/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_4/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_5/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_5/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_5/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_6/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_6/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_6/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv6/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 192)
pfld_inference/conv6/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 192)
pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 12)
pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 12)
pfld_inference/conv6/inbottleneck/add:0 (?, 11, 11, 12)
pfld_inference/conv7/Relu6:0 (?, 6, 6, 24)
Traceback (most recent call last):
  File "save_model.py", line 174, in <module>
    main(parse_arguments(sys.argv[1:]))
  File "save_model.py", line 91, in main
    image_batch, landmark_batch, phase_train_placeholder, args)
  File "/usr/src/app/pfld.py", line 186, in create_model
    features, landmarks_pre = pfld_backbone(input, args.weight_decay, batch_norm_params, args.num_labels, args.depth_multi)
  File "/usr/src/app/pfld.py", line 119, in pfld_backbone
    conv8 = slim.conv2d(conv7, num_channel, [7, 7], stride=1, padding='VALID', scope='conv8')
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py", line 1159, in convolution2d
    conv_dims=2)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 182, in func_with_args
    return func(*args, **current_args)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py", line 1057, in convolution
    outputs = layer.apply(inputs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 1479, in apply
    return self.__call__(inputs, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py", line 537, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 634, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py", line 149, in wrapper
    raise e.ag_error_metadata.to_exception(type(e))
ValueError: in converted code:
    relative to /usr/local/lib/python3.6/dist-packages/tensorflow/python:

    keras/layers/convolutional.py:196 call *
        outputs = self._convolution_op(inputs, self.kernel)
    ops/nn_ops.py:1079 __call__
        return self.conv_op(inp, filter)
    ops/nn_ops.py:635 __call__
        return self.call(inp, filter)
    ops/nn_ops.py:234 __call__
        name=self.name)
    ops/nn_ops.py:1953 conv2d
        name=name)
    ops/gen_nn_ops.py:1071 conv2d
        data_format=data_format, dilations=dilations, name=name)
    framework/op_def_library.py:788 _apply_op_helper
        op_def=op_def)
    util/deprecation.py:507 new_func
        return func(*args, **kwargs)
    framework/ops.py:3616 create_op
        op_def=op_def)
    framework/ops.py:2027 __init__
        control_input_ops)
    framework/ops.py:1867 _create_c_op
        raise ValueError(str(e))

    ValueError: Negative dimension size caused by subtracting 7 from 6 for 'pfld_inference/conv8/Conv2D' (op: 'Conv2D') with input shapes: [?,6,6,24], [7,7,24,96].

]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# vi [Km pfld.py[K[K[K_new.py 
[?2004h[?1049h[22;0;0t[?1h=[?2004h[1;13r[?12h[?12l[27m[23m[29m[m[H[2J[?25l[13;1H"pfld_new.py" 194L, 9429C[2;1H▽[6n[2;1H  [1;1H[>c]10;?]11;?[1;1H[35mfrom[m __future__ [35mimport[m print_function
[35mimport[m tensorflow [38;5;130mas[m tf
[35mimport[m tensorflow.contrib.slim [38;5;130mas[m slim
[35mfrom[m utils [35mimport[m LandmarkImage, LandmarkImage_98

[35mimport[m time


[38;5;130mdef[m [36mconv2d[m(net, stride, channel, kernel, scope):
    net = slim.conv2d(net, channel, [kernel, kernel], stride=stride, scope=scope)[12;5H[36mprint[m(net.name, net.get_shape())[13;84H10,0-1[9C1%[7;1H[?25h[?12$p[?25l[13;74H/[7;1H[13;1H[K[13;1H/[?2004h[?25hc[?25l[1;12r[1;1H[2M[1;13r[7;5H[7m[36mc[m[12;5H[38;5;130mreturn[m net[13;1H[K[13;84H12,5[11C2%/c[13;84H[K[13;3H[?25ho[?25l[7;6H[7m[36mo[m[13;84H12,5[11C2%[13;84H[K[13;4H[?25hn[?25l[7;7H[7m[36mn[m[13;84H12,5[11C2%[13;84H[K[13;5H[?25hv[?25l[7;8H[7m[36mv[m[13;84H12,5[11C2%[13;84H[K[13;6H[?25h8[?25l[27m[23m[29m[m[H[2J[1;13Hconv6 = invertedbottleneck(conv5_6, stride=[31m1[m, up_sample=[31m2[m, channel=[31m16[m, depth=depth, scopee[2;1H=[31m'conv6/inbottleneck'[m)[3;13H[34m# 14*14*16 / conv3*3 / c:32,n:1,s:2[m[4;13Hconv7 = conv2d(conv6, stride=[31m2[m, channel=[31m32[m, kernel=[31m3[m, scope=[31m'conv7'[m)[5;13H[34m# 7*7*32 / conv7*7 / c:128,n:1,s:1[6;13H# [m[7m[34mconv8[m[34m = slim.conv2d(conv7, 128, [7, 7], stride=1, padding='VALID', scope='conv8')[7;13H# for img size84[m[8;13Hconv8 = slim.conv2d(conv7, num_channel, [[31m5[m, [31m5[m], stride=[31m1[m, padding=[31m'VALID'[m, scope=[31m'conv8'[m)[9;13H[36mprint[m(conv8.name, conv8.get_shape())[10;13Havg_pool1 = slim.avg_pool2d(conv6, [conv6.get_shape()[[31m1[m], conv6.get_shape()[[31m2[m]], stride=[31m11[m[11;1H)[12;13H[36mprint[m(avg_pool1.name, avg_pool1.get_shape())[13;84H116,15[8C60%/conv8[13;84H[K[13;7H[?25h[?25l[6;15H[34mconv8[m[13;84H116,15[8C60%[6;15H[?25h[?25l[13;74Hi[6;15H[13;74H [6;15H[13;1H[1m-- INSERT --[m[13;84H[K[13;84H116,15[8C60%[6;15H[?25h[?25l[34mconv8 = slim.conv2d(conv7, 128, [7, 7], stride=1, padding='VALID', scope='conv8')[m[6;95H[K[13;89H4[6;14H[?25h[?25lconv8 = slim.conv2d(conv7, [31m128[m, [[31m7[m, [31m7[m], stride=[31m1[m, padding=[31m'VALID'[m, scope=[31m'conv8'[m)[6;94H[K[13;89H3[6;13H[?25h[?25l[34m#conv8 = slim.conv2d(conv7, 128, [7, 7], stride=1, padding='VALID', scope='conv8')[m[13;89H4[6;14H[?25h[?25l[34m conv8 = slim.conv2d(conv7, 128, [7, 7], stride=1, padding='VALID', scope='conv8')[m[13;89H5[6;15H[?25h[?25l[13;86H7[7;15H[?25h[?25l[1;12r[1;1H[2M[1;13r[11;13Havg_pool2 = slim.avg_pool2d(conv7, [conv7.get_shape()[[31m1[m], conv7.get_shape()[[31m2[m]], stride=[31m11[m[12;1H)[13;84H[K[13;84H118,15[8C60%[6;15H[?25h[13;1H[K[6;14H[?25l[13;74H^[[6;14H[13;74H  [6;15H[13;84H118,14[8C60%[6;14H[?25h[?25l[13;74H:[6;14H[13;74H[K[13;1H:[?2004h[?25hW[?25l[?25hq[?25l[?25h[?25l[97m[41mE492: Not an editor command: Wq[6;14H[m[13;84H118,14[8C60%[6;14H[?25h[?25l[13;74H:[6;14H[13;1H[K[13;1H:[?2004h[?25hq[?25l[?25h[?25l[97m[41mE37: No write since last change (add ! to override)[?2004h[6;14H[m[13;84H118,14[8C60%[6;14H[?25h[?25l[13;74H:[6;14H[13;1H[K[13;1H:[?2004h[?25hq[?25l[?25h![?25l[?25h[?25l[?2004l[13;1H[K[13;1H[?2004l[?1l>[?25h[?1049l[23;0;0t]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# vim train_model.py 
[?2004h[?1049h[22;0;0t[?1h=[?2004h[1;13r[?12h[?12l[27m[23m[29m[m[H[2J[?25l[13;1H"train_model.py" 449L, 20055C[2;1H▽[6n[2;1H  [1;1H[>c]10;?]11;?[1;17H[38;5;130mif[m [38;5;130mnot[m os.path.exists(metagraph_path):[2;21Hsaver.export_meta_graph(metagraph_path)[3;17H[36mprint[m([31m"save checkpoint: {}"[m.format(checkpoint_path))[5;17H[38;5;130mif[m epoch % [31m20[m == [31m0[m [38;5;130mand[m epoch != [31m0[m:[6;21H[36mprint[m([31m"test start"[m)[7;21Hstart = time.time()[8;21Htest_ME, test_FR, test_loss = test(sess, list_ops, args)[9;21H[36mprint[m([31m"test time: {}"[m .format(time.time() - start))[11;21Hsummary, _, _, _ = sess.run([12;25H[[13;84H226,28[8C50%[6;28H[?25h[?12$p[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;17Hsaver.save(sess, checkpoint_path, global_step=epoch, write_meta_graph=[36mFalse[m)[13;1H[K[13;84H225,28[8C50%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;1H[1;12r[1;1H[L[1;13r[1;17Hmetagraph_path = os.path.join(model_dir, [31m'model.meta'[m)[13;84H[K[13;84H224,0-1[7C49%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;17Hcheckpoint_path = os.path.join(model_dir, [31m'model.ckpt'[m)[13;84H[K[13;84H223,28[8C49%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[13;84H[K[13;84H222,28[8C49%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;17Htrain_write.add_summary(summary, epoch)[13;84H[K[13;84H221,28[8C49%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;17H)[13;84H[K[13;84H220,28[8C48%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21H][13;84H[K[13;84H219,28[8C48%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;25Htrain_loss_l2.assign(train_L2)[13;84H[K[13;84H218,28[8C48%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;1H[1;12r[1;1H[L[1;13r[1;25Htrain_loss.assign(train_L),[13;84H[K[13;84H217,0-1[7C48%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;25Hmerged,[13;84H[K[13;84H216,28[8C48%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;21H[[13;84H[K[13;84H215,17[8C47%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;21H[1;12r[1;1H[L[1;13r[1;17Hsummary, _, _ = sess.run([2;21H[106m[[6;21H][m[13;84H[K[13;84H214,21[8C47%[6;21H[?25h[?25l[13;74H~@k[6;21H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[3;21H[[7;21H][13;84H[K[13;84H213,28[8C47%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;17H[36mprint[m([31m"train time: {}"[m .format(time.time() - start))[13;84H[K[13;84H212,28[8C47%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;17Htrain_L, train_L2 = train(sess, epoch_size, epoch, list_ops, args)[13;84H[K[13;84H211,28[8C46%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hstart = time.time()[6;21H[106m[[10;21H][m[13;84H[K[13;84H210,21[8C46%[6;21H[?25h[?25l[13;74H~@k[6;21H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;17H[36mprint[m([31m"train start"[m)[7;21H[[11;21H][13;84H[K[13;84H209,28[8C46%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;1H[1;12r[1;1H[L[1;13r[13;84H[K[13;84H208,0-1[7C46%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hlist_ops[[31m'test_next_element'[m] = test_next_element[13;84H[K[13;84H207,28[8C45%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21Hlist_ops[[31m'train_next_element'[m] = train_next_element[13;84H[K[13;84H206,28[8C45%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21Hlist_ops[[31m'test_dataset'[m] = test_dataset[13;84H[K[13;84H205,28[8C45%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hlist_ops[[31m'train_dataset'[m] = train_dataset[13;84H[K[13;84H204,28[8C45%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;1H[1;12r[1;1H[L[1;13r[13;84H[K[13;84H203,0-1[7C45%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21Hlist_ops[[31m'num_test_file'[m] = num_test_file[13;84H[K[13;84H202,28[8C44%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hlist_ops[[31m'num_train_file'[m] = num_train_file[13;84H[K[13;84H201,28[8C44%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[13;84H[K[13;84H200,28[8C44%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21H[36mprint[m([31m'Test number of examples: {}'[m.format(num_test_file))[13;84H[K[13;84H199,28[8C44%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;1H[1;12r[1;1H[L[1;13r[1;21H[36mprint[m([31m'Total number of examples: {}'[m.format(num_train_file))[13;84H[K[13;84H198,0-1[7C43%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H197,28[8C43%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21Htest_next_element = test_iterator.get_next()[13;84H[K[13;84H196,28[8C43%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;1H[1;12r[1;1H[L[1;13r[1;21Htest_iterator = batch_test_dataset.make_one_shot_iterator()[13;84H[K[13;84H195,0-1[7C43%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21Hbatch_test_dataset = test_dataset.batch(args.batch_size).repeat()[13;84H[K[13;84H194,28[8C43%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[13;84H[K[13;84H193,28[8C42%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Htrain_next_element = train_iterator.get_next()[13;84H[K[13;84H192,0-1[7C42%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21Htrain_iterator = batch_train_dataset.make_one_shot_iterator()[13;84H[K[13;84H191,28[8C42%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hbatch_train_dataset = train_dataset.batch(args.batch_size).repeat()[13;84H[K[13;84H190,28[8C42%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[13;84H[K[13;84H189,28[8C41%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hnum_test_file = test_loader.num_file[13;84H[K[13;84H188,0-1[7C41%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;21H_, test_dataset = test_loader.gen_tfrecord()[13;84H[K[13;84H187,28[8C41%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21H[36mprint[m([31m"============ get test data ==============="[m)[13;84H[K[13;84H186,28[8C41%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hnum_train_file = train_loader.num_file[13;84H[K[13;84H185,28[8C40%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21H_, train_dataset = train_loader.gen_tfrecord()[13;84H[K[13;84H184,0-1[7C40%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21H[36mprint[m([31m"============ get train data ==============="[m)[13;84H[K[13;84H183,28[8C40%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[38;5;130mif[m (epoch % [31m5[m == [31m0[m) [38;5;130mor[m ([31m"train_next_element"[m [38;5;130mnot[m [38;5;130min[m list_ops):[13;84H[K[13;84H182,28[8C40%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;17H[34m# epoch 5の倍数の時のみdata shuffle and augment 作成[m[13;84H[K[13;84H181,28[8C40%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[34m# shuffle and data augment [m[13;84H[K[13;84H180,28[8C39%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[38;5;130mfor[m epoch [38;5;130min[m [36mrange[m(epoch_start, args.max_epoch):[13;84H[K[13;84H179,28[8C39%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H178,28[8C39%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H177,28[8C39%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Htrain_write = tf.summary.FileWriter(log_dir, sess.graph)[13;84H[K[13;84H176,29-28     38%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;13Hmerged = tf.summary.merge_all()[13;84H[K[13;84H175,28[8C38%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H174,28[8C38%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[34m#     save_image_example(sess, list_ops, args)[m[13;84H[K[13;84H173,0-1[7C38%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[34m# if args.save_image_example:[m[13;84H[K[13;84H172,0-1[7C37%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H171,28[8C37%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hsaver.restore(sess, model_path)[13;84H[K[13;84H170,28[8C37%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21H[36mprint[m([31m'Checkpoint file: {}'[m.format(model_path))[13;84H[K[13;84H169,0-1[7C37%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hepoch_start = [36mint[m(model_path[model_path.find([31m'model.ckpt-'[m) + [31m11[m:]) + [31m1[m[13;84H[K[13;84H168,28[8C37%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21H[38;5;130massert[m (ckpt [38;5;130mand[m model_path)[13;84H[K[13;84H167,28[8C36%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hmodel_path = ckpt.model_checkpoint_path[13;84H[K[13;84H166,0-1[7C36%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hckpt = tf.train.get_checkpoint_state(pretrained_model)[13;84H[K[13;84H165,28[8C36%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21H[36mprint[m([31m'Model directory: {}'[m.format(pretrained_model))[13;84H[K[13;84H164,28[8C36%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[38;5;130melse[m:[13;84H[K[13;84H163,28[8C35%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Hsaver.restore(sess, args.pretrained_model)[6;28H[106m([19C)[m[13;84H[K[13;84H162,28[8C35%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21H[36mprint[m([31m'Restoring pretrained model: {}'[m.format(pretrained_model))[7;28H([19C)[13;84H[K[13;84H161,28[8C35%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[38;5;130mif[m ([38;5;130mnot[m os.path.isdir(pretrained_model)):[13;84H[K[13;84H160,28[8C35%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[36mprint[m([31m"path: "[m, os.path.isdir(pretrained_model))[13;84H[K[13;84H159,28[8C35%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;21H[1;12r[1;1H[L[1;13r[1;17Hpretrained_model = args.pretrained_model[13;84H[K[13;84H158,21[8C34%[6;21H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[38;5;130mif[m args.pretrained_model:[13;84H[K[13;84H157,28[8C34%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m"================= resotre pretrain if exist ================="[m)[13;84H[K[13;84H156,28[8C34%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[34m# ============ resotre pretrain =============[m[13;84H[K[13;84H155,28[8C34%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Hepoch_start = [31m0[m[13;84H[K[13;84H154,28[8C33%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H153,28[8C33%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[38;5;130mwith[m sess.as_default():[13;84H[K[13;84H152,28[8C33%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H151,28[8C33%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[34m# =============== finish creating graph =============[m[13;84H[K[13;84H150,28[8C32%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H149,27[8C32%[6;27H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hsess.run(tf.local_variables_initializer())[13;84H[K[13;84H148,0-1[7C32%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hsess.run(tf.global_variables_initializer())[13;84H[K[13;84H147,28[8C32%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9Hsess = tf.Session(graph=g, config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placemenn[2;1Ht=[36mFalse[m, log_device_placement=[36mFalse[m))[13;84H[K[13;84H146,0-1[7C31%[7;1H[?25h[?25l[13;86H5,28 [6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hgpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=[31m1.0[m)[13;84H[K[13;84H144,0-1[7C31%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H143,28[8C31%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;9Hsaver = tf.train.Saver(save_params, max_to_keep=[36mNone[m)[13;84H[K[13;84H142,28[8C31%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[2;9Hsave_params = tf.trainable_variables()[13;84H[K[13;84H141,28[8C30%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htf.summary.scalar([31m'train_loss_l2'[m, train_loss_l2)[13;84H[K[13;84H140,28[8C30%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htf.summary.scalar([31m'train_loss'[m, train_loss)[13;84H[K[13;84H139,0-1[7C30%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htf.summary.scalar([31m'test_10_loss'[m, test_10_loss)[13;84H[K[13;84H138,28[8C30%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htf.summary.scalar([31m'test_failure_rate'[m, test_failure_rate)[13;84H[K[13;84H137,28[8C29%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htf.summary.scalar([31m'test_mean_error'[m, test_mean_error)[13;84H[K[13;84H136,0-1[7C29%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htrain_loss_l2 = tf.Variable(tf.constant([31m0.0[m), dtype=tf.float32, name=[31m'TrainLoss2'[m)[12;1H[94m@@@                                                                                                  [m[13;84H[K[13;84H135,28[8C29%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htrain_loss = tf.Variable(tf.constant([31m0.0[m), dtype=tf.float32, name=[31m'TrainLoss'[m)[13;84H[K[13;84H134,28[8C29%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htest_10_loss = tf.Variable(tf.constant([31m0.0[m), dtype=tf.float32, name=[31m'TestLoss'[m)[13;84H[K[13;84H133,28[8C29%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htest_failure_rate = tf.Variable(tf.constant([31m0.0[m), dtype=tf.float32, name=[31m'FR'[m)[13;84H[K[13;84H132,28[8C28%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htest_mean_error = tf.Variable(tf.constant([31m0.0[m), dtype=tf.float32, name=[31m'ME'[m)[13;84H[K[13;84H131,28[8C28%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H130,28[8C28%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'lr_op'[m] = lr_op[13;84H[K[13;84H129,28[8C28%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'train_op'[m] = train_op[13;84H[K[13;84H128,28[8C27%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'loss'[m] = loss_sum[13;84H[K[13;84H127,28[8C27%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'L2_loss'[m] = L2_loss[13;84H[K[13;84H126,28[8C27%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'landmarks'[m] = landmarks_pre[13;84H[K[13;84H125,0-1[7C27%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H124,28[8C27%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htrain_op, lr_op = train_model(loss_sum, global_step, num_train_file, args)[6;17H[106m[[10C][m[13;84H[K[13;84H123,28[8C26%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[7;17H[[10C][13;84H[K[13;84H122,28[8C26%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m"no quantize, so float: "[m, args.num_quant)[13;84H[K[13;84H121,28[8C26%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[38;5;130melse[m:[13;84H[K[13;84H120,28[8C26%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;45Hquant_delay=[31m2000000[m)  [34m# about in WFLW 6 epoch[m[13;84H[K[13;84H119,0-1[7C25%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Htf.contrib.quantize.create_training_graph(input_graph=g,[13;84H[K[13;84H118,28[8C25%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m            """[m[13;84H[K[13;84H117,0-1[7C25%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m            )[m[13;84H[K[13;84H116,28[8C25%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                scope=None[m[13;84H[K[13;84H115,13[8C24%[6;13H[?25h[?25l[13;74H~@k[6;13H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;1H[31m                freeze_bn_delay=None,[m[13;84H[K[13;84H114,28[8C24%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                quant_delay=0,[m[13;84H[K[13;84H113,28[8C24%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                symmetric=False,[m[13;84H[K[13;84H112,15[8C24%[6;15H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                activation_bits=args.num_quant,[m[13;84H[K[13;84H111,13[8C24%[6;13H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                weight_bits=args.num_quant,[m[13;84H[K[13;84H110,26[8C23%[6;26H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                input_graph=g,[m[13;84H[K[13;84H109,28[8C23%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m            tf.contrib.quantize.experimental_create_training_graph([m[13;84H[K[13;84H108,28[8C23%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[31m"""[m[13;84H[K[13;84H107,28[8C23%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m"quantize by: "[m, args.num_quant)[13;84H[K[13;84H106,28[8C22%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m"====================================="[m)[13;84H[K[13;84H105,28[8C22%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[38;5;130mif[m args.num_quant < [31m64[m:[13;84H[K[13;84H104,28[8C22%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[34m# quantize[m[13;84H[K[13;84H103,28[8C22%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H102,15[8C21%[6;15H[?25h[?25l[13;74H~@k[6;15H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;9Hloss_sum += L2_loss[13;84H[K[13;84H101,28[8C21%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hloss_sum = tf.reduce_mean(loss_sum * _sum_k)[34m#  * attributes_w_n)[m[13;84H[K[13;84H100,28[8C21%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hloss_sum = tf.reduce_sum(tf.square(landmark_batch - landmarks_pre), axis=[31m1[m)[13;84H[K[13;84H99,28[9C21%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9H_sum_k = tf.reduce_sum(tf.map_fn([38;5;130mlambda[m x: [31m1[m - tf.cos([36mabs[m(x)), euler_angles_gt_batch - euler__[2;1Hangles_pre), axis=[31m1[m)[13;84H[K[13;84H98,18[9C21%[7;18H[?25h[?25l[13;85H7,0-1[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9HL2_loss = tf.add_n(tf.losses.get_regularization_losses())[13;84H[K[13;84H96,27[9C20%[6;27H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H95,28[9C20%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'attributes_w_n_batch'[m] = attributes_w_n[13;84H[K[13;84H94,28[9C20%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9Hattributes_w_n = tf.convert_to_tensor(attributes_w_n * mat_ratio)[2;9Hattributes_w_n = tf.reduce_sum(attributes_w_n, axis=[31m1[m)[13;84H[K[13;84H93,28[9C19%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9Hmat_ratio = tf.map_fn([38;5;130mlambda[m x: (tf.cond(x > [31m0[m, [38;5;130mlambda[m: [31m1[m / x, [38;5;130mlambda[m: [36mfloat[m(args.batch_size))[2;1H)), mat_ratio)[13;84H[K[13;84H92,28[9C19%[7;28H[?25h[?25l[13;85H1,0-1[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;9Hmat_ratio = tf.reduce_mean(attributes_w_n, axis=[31m0[m)[13;84H[K[13;84H90,28[9C19%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[34m# _num = attributes_w_n.shape[0][m[13;84H[K[13;84H89,28[9C19%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hattributes_w_n = tf.to_float(attribute_batch[:, [31m1[m:[31m6[m])[13;84H[K[13;84H88,28[9C18%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;72Hphase_train_placeholder, args)[13;84H[K[13;84H87,28[9C18%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlandmarks_pre, landmarks_loss, euler_angles_pre = create_model(image_batch, landmark_batch,[13;84H[K[13;84H86,28[9C18%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9H[34m#                                                                                phase_train__[2;1Hplaceholder, args)[m[13;84H[K[13;84H85,28[9C17%[7;28H[?25h[?25l[13;85H4[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[34m# total_loss, landmarks, heatmaps_loss, heatmaps= create_model(image_batch, landmark_batch,\[m[13;84H[K[13;84H83,0-1[8C17%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[36mprint[m([31m'Building training graph.'[m)[13;84H[K[13;84H82,28[9C17%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[12;1H[94m@@@                                                                                                  [m[13;84H[K[13;84H81,28[9C17%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9Hphase_train_placeholder = tf.placeholder(tf.bool, name=[31m'phase_train'[m)[2;9Hlist_ops[[31m'phase_train_placeholder'[m] = phase_train_placeholder[13;84H[K[13;84H80,28[9C16%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;9H[34m# input node[m[13;84H[K[13;84H79,28[9C16%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H78,28[9C16%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'euler_angles_gt_batch'[m] = euler_angles_gt_batch[13;84H[K[13;84H77,0-1[8C16%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'attribute_batch'[m] = attribute_batch[13;84H[K[13;84H76,28[9C15%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'landmark_batch'[m] = landmark_batch[13;84H[K[13;84H75,28[9C15%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'image_batch'[m] = image_batch[12;1H[94m@@@                                                                                                  [m[13;84H[K[13;84H74,20[9C15%[6;20H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H73,0-1[8C15%[6;1H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9Heuler_angles_gt_batch = tf.placeholder(tf.float32, shape=([36mNone[m, [31m3[m), name=[31m'euler_angles_gt_batt[2;1Hch'[m)[13;84H[K[13;84H72,28[9C15%[7;28H[?25h[?25l[13;85H1[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hattribute_batch = tf.placeholder(tf.int32, shape=([36mNone[m, [31m6[m), name=[31m'attribute_batch'[m)[13;84H[K[13;84H70,28[9C14%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [7;28H[1;12r[1;1H[2L[1;13r[1;9Hlandmark_batch = tf.placeholder(tf.float32, shape=([36mNone[m, args.num_labels*[31m2[m), name=[31m'landmark_bb[2;1Hatch'[m)[13;84H[K[13;84H69,28[9C14%[7;28H[?25h[?25l[13;85H8,0-1[6;1H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9H[36mprint[m([31m"landmark labels num: "[m, args.num_labels*[31m2[m)[2;9Htime.sleep([31m3[m)[13;84H[K[13;84H67,28[9C14%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;38Hname=[31m'image_batch'[m)[13;84H[K[13;84H66,28[9C13%[6;28H[?25h[?25l[1;12r[1;1H[2L[1;13r[1;9H[34m# input node[m[2;9Himage_batch = tf.placeholder(tf.float32, shape=([36mNone[m, args.image_size, args.image_size, [31m3[m),[13;84H[K[13;84H65,28[9C13%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[36mprint[m([31m"=================== create models ==============="[m)[6;19H[106m([1C)[m[13;84H[K[13;84H64,21[9C13%[6;21H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[34m# ================== create models ================[m[7;19H([1C)[13;84H[K[13;84H63,28[9C12%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[12;1H[94m@@@                                                                                                  [m[13;84H[K[13;84H62,28[9C12%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops[[31m'global_step'[m] = global_step[13;84H[K[13;84H61,28[9C12%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hglobal_step = tf.Variable([31m0[m, trainable=[36mFalse[m)[13;84H[K[13;84H60,20[9C12%[6;20H[?25h[?25l[13;74H~@k[6;20H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;9Htf.set_random_seed(args.seed)[12;1H[94m@@@                                                                                                  [m[13;84H[K[13;84H59,28[9C12%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H58,28[9C11%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H57,4[10C11%[6;4H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[36mprint[m([31m'Number of batches per epoch: {}'[m.format(epoch_size))[13;84H[K[13;84H56,28[9C11%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[36mprint[m([31m"num train file :"[m, num_train_file)[13;84H[K[13;84H55,28[9C11%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hepoch_size = num_train_file // args.batch_size[13;84H[K[13;84H54,28[9C10%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H53,0-1[8C10%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hnum_train_file = train_loader.num_file[13;84H[K[13;84H52,0-1[8C10%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htest_loader = DataLoader(args.test_list, args, [31m"test"[m, debug)[13;84H[K[13;84H51,28[9C10%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Htrain_loader = DataLoader(args.file_list, args, [31m"train"[m, debug)[13;84H[K[13;84H50,28[9C10%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[36mprint[m([31m"============== get dataloader =============="[m)[13;84H[K[13;84H49,28[10C9%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[34m# ============== get dataset ==============[m[13;84H[K[13;84H48,0-1[9C9%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H47,28[10C9%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hos.makedirs(model_dir, exist_ok=[36mTrue[m)[13;84H[K[13;84H46,28[10C9%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[36mprint[m([31m'Model dir: {}'[m.format(model_dir))[13;84H[K[13;84H45,28[10C8%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hmodel_dir = args.model_dir[13;84H[K[13;84H44,28[10C8%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H43,28[10C8%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlist_ops = {}[13;84H[K[13;84H42,0-1[9C8%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;5H[38;5;130mwith[m tf.Graph().as_default() [38;5;130mas[m g:[13;84H[K[13;84H41,28[10C8%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H40,28[10C7%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5Htime.sleep([31m3[m)[13;84H[K[13;84H39,28[10C7%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5Hnp.random.seed(args.seed)[13;84H[K[13;84H38,0-1[9C7%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5H[36mprint[m([31m"args: "[m, args)[6;20H[106m{}[m[13;84H[K[13;84H37,21[10C7%[6;21H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5Hdebug = (args.debug == [31m'True'[m)[7;20H{}[13;84H[K[13;84H36,28[10C6%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[38;5;130mdef[m [36mmain[m(args):[13;84H[K[13;84H35,0-1[9C6%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[6;15H[106m([1C)[m[13;84H[K[13;84H34,17[10C6%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[7;15H([1C)[13;84H[K[13;84H33,28[10C6%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1Hlog_dir = [31m'./tensorboard'[m[6;10H[106m([14C)[m[13;84H[K[13;84H32,25[10C5%[6;25H[?25h[?25l[1;12r[1;1H[L[1;13r[7;10H([14C)[13;84H[K[13;84H31,28[10C5%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H30,15[10C5%[6;15H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[34m# matplotlib.use('Agg')[m[13;84H[K[13;84H29,0-1[9C5%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[34m# import matplotlib[m[13;84H[K[13;84H28,0-1[9C5%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m shutil[13;84H[K[13;84H27,25[10C4%[6;25H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m sys[13;84H[K[13;84H26,0-1[9C4%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m argparse[13;84H[K[13;84H25,0-1[9C4%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;23H[1;12r[1;1H[L[1;13r[1;1H[35mimport[m cv2[13;84H[K[13;84H24,23[10C4%[6;23H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m numpy [38;5;130mas[m np[13;84H[K[13;84H23,19[10C3%[6;19H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m tensorflow.python.framework [35mimport[m graph_util[13;84H[K[13;84H22,13[10C3%[6;13H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m tensorflow [38;5;130mas[m tf[13;84H[K[13;84H21,10[10C3%[6;10H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H20,15[10C3%[6;15H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[34m# print('pid: {}     GPU: {}'.format(os.getpid(), os.environ['CUDA_VISIBLE_DEVICES']))[m[13;84H[K[13;84H19,10[10C2%[6;10H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[34m# os.environ['CUDA_VISIBLE_DEVICES'] = '2'[m[13;84H[K[13;84H18,18[10C2%[6;18H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m os[13;84H[K[13;84H17,28[10C2%[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [6;23H[1;12r[1;1H[L[1;13r[1;1H[34m# import matplotlib.pyplot as plt[m[13;84H[K[13;84H16,23[10C2%[6;23H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m math[13;84H[K[13;84H15,0-1[9C2%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m time[13;84H[K[13;84H14,28[10C1%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m data_augmentor [35mimport[m DataAugmentator[13;84H[K[13;84H13,28[10C1%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m generate_data [35mimport[m DataLoader[13;84H[K[13;84H12,9[11C1%[6;9H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m pfld_new [35mimport[m create_model[13;84H[K[13;84H11,28[10C1%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m utils [35mimport[m train_model[13;84H[K[13;84H10,11[10C0%[6;11H[?25h[?25l[13;74H~@k[6;11H[13;74H   [6;11H[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m __future__ [35mimport[m print_function[13;84H[K[13;84H9,11[11C0%[6;11H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m __future__ [35mimport[m division[13;84H[K[13;84H8,28[11C0%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m __future__ [35mimport[m absolute_import[13;84H[K[13;84H7,28[11C0%[6;28H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[34m# -*- coding: UTF-8 -*-[m[13;84H[K[13;84H6,28[10CTop[6;28H[?25h[?25l[13;84H5[5;28H[?25h[?25l[13;84H4[4;28H[?25h[?25l[13;84H3[3;28H[?25h[?25l[13;84H2[2;28H[?25h[?25l[13;74H~@k[2;28H[13;74H   [1;23H[13;84H1,23[1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [1;23H[?25h[?25l[13;74H~@k[1;23H[13;74H   [2;28H[13;84H2,28[2;28H[?25h[?25l[13;74H~@k[2;28H[13;74H   [3;28H[13;84H3[3;28H[?25h[?25l[13;74H~@k[3;28H[13;74H   [4;28H[13;84H4[4;28H[?25h[?25l[13;74H~@k[4;28H[13;74H   [5;28H[13;84H5[5;28H[?25h[?25l[13;74H~@k[5;28H[13;74H   [6;28H[13;84H6[6;28H[?25h[?25l[13;74H~@k[6;28H[13;74H   [7;28H[13;84H7[7;28H[?25h[?25l[13;74H~@k[7;28H[13;74H   [7;28H[1;12r[12;1H
[1;13r[12;1H[34m# os.environ['CUDA_VISIBLE_DEVICES'] = '2'[m[13;84H[K[13;84H8,28[11C0%[7;28H[?25h[?25l[13;74H~@k[7;28H[13;74H   [7;11H[1;12r[12;1H
[1;13r[12;1H[34m# print('pid: {}     GPU: {}'.format(os.getpid(), os.environ['CUDA_VISIBLE_DEVICES']))[m[13;84H[K[13;84H9,11[11C0%[7;11H[?25h[?25l[13;74H~@k[7;11H[13;74H   [7;11H[1;12r[12;1H
[1;13r[13;84H[K[13;84H10,11[10C0%[7;11H[?25h[?25l[13;74H~@k[7;11H[13;74H   [7;28H[1;12r[12;1H
[1;13r[12;1H[35mimport[m tensorflow [38;5;130mas[m tf[13;84H[K[13;84H11,28[10C0%[7;28H[?25h[?25l[13;74H:[7;28H[13;74H[K[13;1H:[?2004h[?25hq[?25l[?25h[?25l[?2004l[13;1H[K[13;1H[?2004l[?1l>[?25h[?1049l[23;0;0t]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# /convvim train_model.py 
[?2004h[?1049h[22;0;0t[?1h=[?2004h[1;13r[?12h[?12l[27m[23m[29m[m[H[2J[?25l[13;1H"train_model.py" 449L, 20055C[2;1H▽[6n[2;1H  [1;1H[>c]10;?]11;?[1;1H[35mfrom[m utils [35mimport[m train_model
[35mfrom[m pfld_new [35mimport[m create_model
[35mfrom[m generate_data [35mimport[m DataLoader
[35mfrom[m data_augmentor [35mimport[m DataAugmentator
[35mimport[m time
[35mimport[m math
[34m# import matplotlib.pyplot as plt[m
[35mimport[m os
[34m# os.environ['CUDA_VISIBLE_DEVICES'] = '2'
# print('pid: {}     GPU: {}'.format(os.getpid(), os.environ['CUDA_VISIBLE_DEVICES']))[m

[35mimport[m tensorflow [38;5;130mas[m tf[13;84H11,28[10C0%[7;28H[?25h[?12$p[?25l[13;74H:[7;28H[13;1H[K[13;1H:[?2004h[?25hQ[?25l[?25h[?25l[97m[41mE492: Not an editor command: Q[7;28H[m[13;84H11,28[10C0%[7;28H[?25h[?25l[13;74H~@k[7;28H[13;74H   [6;11H[13;85H0,11[6;11H[?25h[?25l[13;74H~@k[6;11H[13;74H   [6;11H[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m __future__ [35mimport[m print_function[13;1H[K[13;84H9,11[11C0%[6;11H[?25h[?25l[13;74H~@k[6;11H[13;74H   [6;28H[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m __future__ [35mimport[m division[13;84H[K[13;84H8,28[11C0%[6;28H[?25h[?25l[13;74H:[6;28H[13;74H[K[13;1H:[?2004h[?25hq[?25l[?25h[?25l[?2004l[13;1H[K[13;1H[?2004l[?1l>[?25h[?1049l[23;0;0t]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# vim train_model.py [3Ppfld_new[C[C[C[C
[?2004h[?1049h[22;0;0t[?1h=[?2004h[1;13r[?12h[?12l[27m[23m[29m[m[H[2J[?25l[13;1H"pfld_new.py" 194L, 9429C[2;1H▽[6n[2;1H  [1;1H[>c]10;?]11;?[1;13H[34m# 14*14*16 / conv3*3 / c:32,n:1,s:2[m[2;13Hconv7 = conv2d(conv6, stride=[31m2[m, channel=[31m32[m, kernel=[31m3[m, scope=[31m'conv7'[m)[3;13H[34m# 7*7*32 / conv7*7 / c:128,n:1,s:1[4;13H# conv8 = slim.conv2d(conv7, 128, [7, 7], stride=1, padding='VALID', scope='conv8')[5;13H# for img size84[m[6;13Hconv8 = slim.conv2d(conv7, num_channel, [[31m5[m, [31m5[m], stride=[31m1[m, padding=[31m'VALID'[m, scope=[31m'conv8'[m)[7;13H[36mprint[m(conv8.name, conv8.get_shape())[8;13Havg_pool1 = slim.avg_pool2d(conv6, [conv6.get_shape()[[31m1[m], conv6.get_shape()[[31m2[m]], stride=[31m11[m[9;1H)[10;13H[36mprint[m(avg_pool1.name, avg_pool1.get_shape())[11;13Havg_pool2 = slim.avg_pool2d(conv7, [conv7.get_shape()[[31m1[m], conv7.get_shape()[[31m2[m]], stride=[31m11[m[12;1H)[13;84H118,14[8C60%[6;14H[?25h[?12$p[?25l[13;74H.[6;14H[13;74H [6;14H[?25h[?25l[13;74H~@k[6;14H[13;74H   [6;13H[13;89H3[6;13H[?25h[?25l[13;74H:[6;13H[13;1H[K[13;1H:[?2004h[?25hq[?25l[?25h[?25l[?2004l[13;1H[K[13;1H[?2004l[?1l>[?25h[?1049l[23;0;0t]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# vim pfld_new.py [3@train_model[C[C[C[C[3Ppfld_new[C[C[C[C[2Psh run.sh save[3Pvim run.sh sh run.sh savevim pfld_new.py [3@train_model[C[C[C[C[3Ppfld_new[C[C[C[C[Kvim test_model.py 
[?2004h[?1049h[22;0;0t[?1h=[?2004h[1;13r[?12h[?12l[27m[23m[29m[m[H[2J[?25l[13;1H"test_model.py" 230L, 9716C[2;1H▽[6n[2;1H  [1;1H[>c]10;?]11;?[1;21Hannotate_pre_landmark = pre_landmark.reshape(-[31m1[m, [31m2[m) * [h, w][2;21H[38;5;130mfor[m land_id, (x, y) [38;5;130min[m [36menumerate[m(annotate_pre_landmark.astype(np.int32)):[3;25Hcv2.circle(img, (x, y), [31m1[m, ([31m0[m, [31m255[m, [31m0[m), [31m1[m)[4;25Hcv2.imwrite([31m"./show_labeled"[m + [36mstr[m(land_id) + [31m".jpg"[m, img)[5;21Himg = image.copy()[6;21Hannotate_landmark = landmarks[file_id].reshape(-[31m1[m, [31m2[m) * [h, w][7;21H[38;5;130mfor[m land_id, (x, y) [38;5;130min[m [36menumerate[m(annotate_landmark.astype(np.int32)):[8;25Hcv2.circle(img, (x, y), [31m1[m, ([31m0[m, [31m255[m, [31m0[m), [31m1[m)[9;25Hcv2.imwrite([31m"./show_test"[m + [36mstr[m(land_id) + [31m".jpg"[m, img)[10;21H[38;5;130mbreak[m[11;21H[36mprint[m(os.path.join(args.out_dir, filename))[12;21Hcv2.imwrite(os.path.join(args.out_dir, filename), image)[13;84H122,17[8C53%[6;17H[?25h[?12$p[?25l[13;74H:[6;17H[13;1H[K[13;1H:[?2004h[?25hq[?25l[?25h[?25l[?2004l[13;1H[K[13;1H[?2004l[?1l>[?25h[?1049l[23;0;0t]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# vim test_model.py [1P[1P[1P[1P[1@s[1@a[1@v[1@e
[?2004h[?1049h[22;0;0t[?1h=[?2004h[1;13r[?12h[?12l[27m[23m[29m[m[H[2J[?25l[13;1H"save_model.py" 174L, 7334C[2;1H▽[6n[2;1H  [1;1H[>c]10;?]11;?[1;1H[34m# -*- coding: UTF-8 -*-[m
[35mfrom[m __future__ [35mimport[m absolute_import
[35mfrom[m __future__ [35mimport[m division
[35mfrom[m __future__ [35mimport[m print_function

[35mfrom[m pfld [35mimport[m create_model
[35mfrom[m generate_data [35mimport[m DataLoader

[35mimport[m time
[34m# import matplotlib.pyplot as plt[m
[35mimport[m os
[34m# os.environ['CUDA_VISIBLE_DEVICES'] = '2'[m[13;84H1,1[11CTop[1;1H[?25h[?12$p[?25l[13;74H~@k[1;1H[13;74H   [2;1H[13;84H2[2;1H[?25h[?25l[13;74H~@k[2;1H[13;74H   [3;1H[13;84H3[3;1H[?25h[?25l[13;74H~@k[3;1H[13;74H   [4;1H[13;84H4[4;1H[?25h[?25l[13;74H~@k[4;1H[13;74H   [5;1H[13;84H5,0-1[5;1H[?25h[?25l[13;74H~@k[5;1H[13;74H   [6;1H[13;84H6,1  [6;1H[?25h[?25l[13;74Hi[6;1H[13;74H [6;1H[13;1H[1m-- INSERT --[m[13;13H[K[13;84H6,1[11CTop[6;1H[?25h[?25l[13;86H2[6;2H[?25h[?25l[13;86H3[6;3H[?25h[?25l[13;86H4[6;4H[?25h[?25l[13;86H5[6;5H[?25h[?25l[13;86H6[6;6H[?25h[?25l[13;86H7[6;7H[?25h[?25l[13;86H8[6;8H[?25h[?25l[13;86H9[6;9H[?25h[?25l[13;86H10[6;10H[?25h[?25l_ [35mimport[m create_model[13;87H1[6;11H[?25h[?25ln [35mimport[m create_model[13;87H2[6;12H[?25h[?25le [35mimport[m create_model[13;87H3[6;13H[?25h[?25lw [35mimport[m create_model[13;87H4[6;14H[?25h[13;1H[K[6;13H[?25l[13;74H^[[6;13H[13;74H  [6;14H[13;84H6,13[10CTop[6;13H[?25h[?25l[13;74H:[6;13H[13;74H[K[13;1H:[?2004h[?25hw[?25l[?25hq[?25l[?25h[?25l[?2004l"save_model.py" 174L, 7338C written
[?2004l[?1l>[?25h[?1049l[23;0;0t]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# vim save_model.py test[C[C[C[C[C[C[C[C[C[C[2Ppfld_new[C[C[C[C[3@train_model[C[C[C[C[3Ppfld_new[C[C[C[C[2Psh run.sh save[3Pvim run.sh sh run.sh save
run save
['save_model.py', '--model_dir=models2/save_models/68/new_dm075_im84_WFLW68', '--pretrained_model=models2/save_models/68/new_dm075_im84_WFLW68', '--test_list=data/test_moru_dataset/list.txt', '--num_labels=68', '--learning_rate=0.0001', '--level=L1', '--image_size=84', '--batch_size=128', '--depth_multi=0.75', '--num_quant=64', '--is_augment=False']
WARNING: Logging before flag parsing goes to stderr.
W0207 06:16:20.424627 140114559633216 deprecation_wrapper.py:119] From save_model.py:84: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0207 06:16:20.427102 140114559633216 deprecation_wrapper.py:119] From /usr/src/app/pfld_new.py:176: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

labels;  68
labels;  68
W0207 06:16:26.433743 140114559633216 deprecation_wrapper.py:119] From /usr/src/app/pfld_new.py:75: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

PFLD input shape(image_batch:0): (?, 84, 84, 3)
pfld_inference/conv1/Relu6:0 (?, 42, 42, 64)
W0207 06:16:26.644302 140114559633216 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
pfld_inference/conv2/dwise/Relu6:0 (?, 42, 42, 48)
pfld_inference/conv3_1/inbottleneck/conv2d_1/Relu6:0 (?, 42, 42, 96)
pfld_inference/conv3_1/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_2/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_2/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_2/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_3/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_3/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_3/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_4/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_4/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_4/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_5/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_5/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_5/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv4/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv4/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 96)
pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_1/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_1/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_1/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_2/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_2/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_2/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_3/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_3/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_3/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_4/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_4/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_4/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_5/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_5/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_5/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_6/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_6/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_6/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv6/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 192)
pfld_inference/conv6/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 192)
pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 12)
pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 12)
pfld_inference/conv6/inbottleneck/add:0 (?, 11, 11, 12)
pfld_inference/conv7/Relu6:0 (?, 6, 6, 32)
pfld_inference/conv8/Relu6:0 (?, 2, 2, 48)
pfld_inference/AvgPool2D/AvgPool:0 (?, 1, 1, 12)
pfld_inference/AvgPool2D_1/AvgPool:0 (?, 1, 1, 32)
W0207 06:16:28.126161 140114559633216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
last layer name
pfld_inference/fc/BiasAdd:0 (?, 136)

auxiliary net
pfld_conv1/Relu:0 (?, 11, 11, 128)
pfld_conv2/Relu:0 (?, 11, 11, 128)
pfld_conv3/Relu:0 (?, 6, 6, 32)
pfld_conv4/Relu:0 (?, 6, 6, 128)
pool1/MaxPool:0 (?, 6, 6, 128)
Flatten/flatten/Reshape:0 (?, 4608)
pfld_fc1/BatchNorm/Reshape_1:0 (?, 32)
pfld_fc2/BatchNorm/Reshape_1:0 (?, 3)
==========finish define graph===========
W0207 06:16:28.761329 140114559633216 deprecation_wrapper.py:119] From save_model.py:93: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0207 06:16:28.761566 140114559633216 deprecation_wrapper.py:119] From save_model.py:94: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

no quantize, so float:  64
W0207 06:16:28.939499 140114559633216 deprecation_wrapper.py:119] From save_model.py:114: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

2020-02-07 06:16:28.939842: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-07 06:16:28.946737: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-02-07 06:16:31.594252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:31.595158: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c43ab0 executing computations on platform CUDA. Devices:
2020-02-07 06:16:31.595191: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2020-02-07 06:16:31.617280: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300050000 Hz
2020-02-07 06:16:31.617595: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x651b210 executing computations on platform Host. Devices:
2020-02-07 06:16:31.617678: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-07 06:16:31.617909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:31.618784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
2020-02-07 06:16:31.619157: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:16:31.620666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:16:31.622054: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-07 06:16:31.622450: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-07 06:16:31.624345: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-07 06:16:31.625814: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-07 06:16:31.629707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-07 06:16:31.629848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:31.630697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:31.631465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-07 06:16:31.631530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:16:31.633212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-07 06:16:31.633240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-07 06:16:31.633260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-02-07 06:16:31.633445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:31.634287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:31.635071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2020-02-07 06:16:32.079724: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 11.17G (11996954624 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
Model directory: models2/save_models/68/new_dm075_im84_WFLW68
ckpt: model_checkpoint_path: "models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt-89"
all_model_checkpoint_paths: "models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt-89"

Checkpoint file: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt-89
W0207 06:16:32.760563 140114559633216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
<tf.Variable 'pfld_inference/conv1/weights:0' shape=(3, 3, 3, 64) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv2/dwise/depthwise_weights:0' shape=(3, 3, 64, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv2/dwise/pointwise_weights:0' shape=(1, 1, 64, 48) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv2/dwise/BatchNorm/beta:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv2/dwise/BatchNorm/moving_mean:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv2/dwise/BatchNorm/moving_variance:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 48, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 96, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 96, 48) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 48, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 96, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 96, 48) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 48, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 96, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 96, 48) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 48, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 96, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 96, 48) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 48, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 96, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 96, 48) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 48, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 96, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 96, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 96, 384) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 384, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 384, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 96, 384) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 384, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 384, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 96, 384) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 384, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 384, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 96, 384) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 384, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 384, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 96, 384) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 384, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 384, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 96, 384) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 384, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/beta:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(384,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 384, 96) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(96,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_1/weights:0' shape=(1, 1, 96, 192) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/beta:0' shape=(192,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/moving_mean:0' shape=(192,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/moving_variance:0' shape=(192,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/separable2d/depthwise_weights:0' shape=(3, 3, 192, 1) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/beta:0' shape=(192,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/moving_mean:0' shape=(192,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/moving_variance:0' shape=(192,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_2/weights:0' shape=(1, 1, 192, 12) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/beta:0' shape=(12,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/moving_mean:0' shape=(12,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/moving_variance:0' shape=(12,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_3/weights:0' shape=(1, 1, 96, 12) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/beta:0' shape=(12,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/moving_mean:0' shape=(12,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/moving_variance:0' shape=(12,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv7/weights:0' shape=(3, 3, 12, 32) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv7/BatchNorm/beta:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv7/BatchNorm/moving_mean:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv7/BatchNorm/moving_variance:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv8/weights:0' shape=(5, 5, 32, 48) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv8/BatchNorm/beta:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv8/BatchNorm/moving_mean:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/conv8/BatchNorm/moving_variance:0' shape=(48,) dtype=float32_ref>
<tf.Variable 'pfld_inference/fc/weights:0' shape=(236, 136) dtype=float32_ref>
<tf.Variable 'pfld_inference/fc/biases:0' shape=(136,) dtype=float32_ref>
<tf.Variable 'pfld_conv1/weights:0' shape=(3, 3, 48, 128) dtype=float32_ref>
<tf.Variable 'pfld_conv1/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_conv1/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_conv1/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_conv2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>
<tf.Variable 'pfld_conv2/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_conv2/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_conv2/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_conv3/weights:0' shape=(3, 3, 128, 32) dtype=float32_ref>
<tf.Variable 'pfld_conv3/BatchNorm/beta:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_conv3/BatchNorm/moving_mean:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_conv3/BatchNorm/moving_variance:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_conv4/weights:0' shape=(7, 7, 32, 128) dtype=float32_ref>
<tf.Variable 'pfld_conv4/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_conv4/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_conv4/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'pfld_fc1/weights:0' shape=(4608, 32) dtype=float32_ref>
<tf.Variable 'pfld_fc1/BatchNorm/beta:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_fc1/BatchNorm/moving_mean:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_fc1/BatchNorm/moving_variance:0' shape=(32,) dtype=float32_ref>
<tf.Variable 'pfld_fc2/weights:0' shape=(32, 3) dtype=float32_ref>
<tf.Variable 'pfld_fc2/BatchNorm/beta:0' shape=(3,) dtype=float32_ref>
<tf.Variable 'pfld_fc2/BatchNorm/moving_mean:0' shape=(3,) dtype=float32_ref>
<tf.Variable 'pfld_fc2/BatchNorm/moving_variance:0' shape=(3,) dtype=float32_ref>
finish check
Save frozen graph
W0207 06:16:33.070404 140114559633216 deprecation.py:323] From save_model.py:34: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W0207 06:16:33.070589 140114559633216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W0207 06:16:33.244640 140114559633216 deprecation_wrapper.py:119] From save_model.py:35: The name tf.train.write_graph is deprecated. Please use tf.io.write_graph instead.

get tensor
start save saved_model
W0207 06:16:33.257277 140114559633216 deprecation_wrapper.py:119] From save_model.py:44: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.

W0207 06:16:33.257593 140114559633216 deprecation_wrapper.py:119] From save_model.py:45: The name tf.saved_model.predict_signature_def is deprecated. Please use tf.compat.v1.saved_model.predict_signature_def instead.

W0207 06:16:33.257744 140114559633216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
W0207 06:16:33.258051 140114559633216 deprecation_wrapper.py:119] From save_model.py:52: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.

W0207 06:16:33.258204 140114559633216 deprecation_wrapper.py:119] From save_model.py:53: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.

finish save saved_model
2020-02-07 06:16:33.914355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:33.914852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
2020-02-07 06:16:33.914948: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:16:33.914996: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:16:33.915031: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-07 06:16:33.915073: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-07 06:16:33.915111: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-07 06:16:33.915148: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-07 06:16:33.915184: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-07 06:16:33.915309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:33.915830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:33.916251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-07 06:16:33.916873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:33.917328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
2020-02-07 06:16:33.917394: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:16:33.917447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:16:33.917495: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-07 06:16:33.917541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-07 06:16:33.917585: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-07 06:16:33.917631: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-07 06:16:33.917680: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-07 06:16:33.917797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:33.918256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:33.918653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-07 06:16:33.918694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-07 06:16:33.918714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-07 06:16:33.918726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-02-07 06:16:33.918893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:33.919376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:33.919809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
W0207 06:16:33.920037 140114559633216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
2020-02-07 06:16:34.597583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:34.598069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
2020-02-07 06:16:34.598162: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:16:34.598200: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:16:34.598236: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-07 06:16:34.598269: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-07 06:16:34.598307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-07 06:16:34.598345: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-07 06:16:34.598382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-07 06:16:34.598488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:34.598964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:34.599353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-07 06:16:34.599390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-07 06:16:34.599412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-07 06:16:34.599425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-02-07 06:16:34.599586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:34.600066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:34.600479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2020-02-07 06:16:35.447056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.447557: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-02-07 06:16:35.447660: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2020-02-07 06:16:35.448413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.448837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
2020-02-07 06:16:35.448935: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:16:35.448977: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:16:35.449013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-07 06:16:35.449047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-07 06:16:35.449080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-07 06:16:35.449118: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-07 06:16:35.449179: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-07 06:16:35.449295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.449786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.450189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-07 06:16:35.450228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-07 06:16:35.450250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-07 06:16:35.450269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-02-07 06:16:35.450412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.450897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.451323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2020-02-07 06:16:35.487241: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2020-02-07 06:16:35.487269: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-02-07 06:16:35.487277: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-07 06:16:35.730896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.731420: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-02-07 06:16:35.731536: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2020-02-07 06:16:35.732125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.732537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
2020-02-07 06:16:35.732634: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:16:35.732672: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:16:35.732702: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-07 06:16:35.732730: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-07 06:16:35.732764: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-07 06:16:35.732814: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-07 06:16:35.732867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-07 06:16:35.732987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.733541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.733968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-07 06:16:35.734011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-07 06:16:35.734033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-07 06:16:35.734045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-02-07 06:16:35.734198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.734707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:35.735139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2020-02-07 06:16:35.749235: E tensorflow/core/grappler/grappler_item_builder.cc:637] Init node pfld_inference/conv1/weights/Assign doesn't exist in graph
finish save tflite

Loading the TF graph...
2020-02-07 06:16:37.483331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:37.483846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
2020-02-07 06:16:37.483952: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:16:37.484004: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:16:37.484045: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-07 06:16:37.484085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-07 06:16:37.484122: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-07 06:16:37.484166: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-07 06:16:37.484205: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-07 06:16:37.484322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:37.484815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:37.485233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-07 06:16:37.485282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-07 06:16:37.485301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-07 06:16:37.485312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-02-07 06:16:37.485467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:37.485950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:16:37.486364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
Graph Loaded.
Now finding ops in the TF graph that can be dropped for inference
2020-02-07 06:16:37.729520: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:16:37.871505: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
Collecting all the 'Const' ops from the graph, by running it....
Done.
Now starting translation to CoreML graph.
Automatic shape interpretation succeeded for input blob image_batch:0
1/563: Analysing op name: pfld_inference/fc/biases ( type:  Const )
2/563: Analysing op name: pfld_inference/fc/biases/read ( type:  Identity )
3/563: Analysing op name: pfld_inference/fc/weights ( type:  Const )
4/563: Analysing op name: pfld_inference/fc/weights/read ( type:  Identity )
5/563: Analysing op name: pfld_inference/concat/axis ( type:  Const )
6/563: Analysing op name: pfld_inference/Flatten_2/flatten/Reshape/shape/1 ( type:  Const )
7/563: Analysing op name: pfld_inference/Flatten_2/flatten/strided_slice/stack_2 ( type:  Const )
8/563: Analysing op name: pfld_inference/Flatten_2/flatten/strided_slice/stack_1 ( type:  Const )
9/563: Analysing op name: pfld_inference/Flatten_2/flatten/strided_slice/stack ( type:  Const )
10/563: Analysing op name: pfld_inference/Flatten_1/flatten/Reshape/shape/1 ( type:  Const )
11/563: Analysing op name: pfld_inference/Flatten_1/flatten/strided_slice/stack_2 ( type:  Const )
12/563: Analysing op name: pfld_inference/Flatten_1/flatten/strided_slice/stack_1 ( type:  Const )
13/563: Analysing op name: pfld_inference/Flatten_1/flatten/strided_slice/stack ( type:  Const )
14/563: Analysing op name: pfld_inference/Flatten/flatten/Reshape/shape/1 ( type:  Const )
15/563: Analysing op name: pfld_inference/Flatten/flatten/strided_slice/stack_2 ( type:  Const )
16/563: Analysing op name: pfld_inference/Flatten/flatten/strided_slice/stack_1 ( type:  Const )
17/563: Analysing op name: pfld_inference/Flatten/flatten/strided_slice/stack ( type:  Const )
18/563: Analysing op name: pfld_inference/conv8/BatchNorm/moving_variance ( type:  Const )
19/563: Analysing op name: pfld_inference/conv8/BatchNorm/moving_variance/read ( type:  Identity )
20/563: Analysing op name: pfld_inference/conv8/BatchNorm/moving_mean ( type:  Const )
21/563: Analysing op name: pfld_inference/conv8/BatchNorm/moving_mean/read ( type:  Identity )
22/563: Analysing op name: pfld_inference/conv8/BatchNorm/Const ( type:  Const )
23/563: Analysing op name: pfld_inference/conv8/BatchNorm/beta ( type:  Const )
24/563: Analysing op name: pfld_inference/conv8/BatchNorm/beta/read ( type:  Identity )
25/563: Analysing op name: pfld_inference/conv8/weights ( type:  Const )
26/563: Analysing op name: pfld_inference/conv8/weights/read ( type:  Identity )
27/563: Analysing op name: pfld_inference/conv7/BatchNorm/moving_variance ( type:  Const )
28/563: Analysing op name: pfld_inference/conv7/BatchNorm/moving_variance/read ( type:  Identity )
29/563: Analysing op name: pfld_inference/conv7/BatchNorm/moving_mean ( type:  Const )
30/563: Analysing op name: pfld_inference/conv7/BatchNorm/moving_mean/read ( type:  Identity )
31/563: Analysing op name: pfld_inference/conv7/BatchNorm/Const ( type:  Const )
32/563: Analysing op name: pfld_inference/conv7/BatchNorm/beta ( type:  Const )
33/563: Analysing op name: pfld_inference/conv7/BatchNorm/beta/read ( type:  Identity )
34/563: Analysing op name: pfld_inference/conv7/weights ( type:  Const )
35/563: Analysing op name: pfld_inference/conv7/weights/read ( type:  Identity )
36/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/moving_variance ( type:  Const )
37/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/moving_variance/read ( type:  Identity )
38/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/moving_mean ( type:  Const )
39/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/moving_mean/read ( type:  Identity )
40/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/Const ( type:  Const )
41/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/beta ( type:  Const )
42/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/beta/read ( type:  Identity )
43/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/weights ( type:  Const )
44/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/weights/read ( type:  Identity )
45/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
46/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
47/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
48/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
49/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
50/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
51/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
52/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/weights ( type:  Const )
53/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/weights/read ( type:  Identity )
54/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
55/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
56/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
57/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
58/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
59/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
60/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
61/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/depthwise_weights ( type:  Const )
62/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
63/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
64/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
65/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
66/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
67/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
68/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
69/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
70/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/weights ( type:  Const )
71/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/weights/read ( type:  Identity )
72/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
73/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
74/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
75/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
76/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
77/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
78/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
79/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/weights ( type:  Const )
80/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/weights/read ( type:  Identity )
81/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
82/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
83/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
84/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
85/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
86/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
87/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
88/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/depthwise_weights ( type:  Const )
89/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
90/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
91/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
92/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
93/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
94/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
95/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
96/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
97/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/weights ( type:  Const )
98/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/weights/read ( type:  Identity )
99/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
100/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
101/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
102/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
103/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
104/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
105/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
106/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/weights ( type:  Const )
107/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/weights/read ( type:  Identity )
108/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
109/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
110/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
111/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
112/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
113/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
114/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
115/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/depthwise_weights ( type:  Const )
116/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
117/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
118/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
119/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
120/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
121/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
122/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
123/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
124/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/weights ( type:  Const )
125/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/weights/read ( type:  Identity )
126/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
127/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
128/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
129/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
130/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
131/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
132/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
133/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/weights ( type:  Const )
134/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/weights/read ( type:  Identity )
135/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
136/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
137/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
138/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
139/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
140/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
141/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
142/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/depthwise_weights ( type:  Const )
143/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
144/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
145/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
146/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
147/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
148/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
149/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
150/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
151/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/weights ( type:  Const )
152/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/weights/read ( type:  Identity )
153/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
154/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
155/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
156/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
157/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
158/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
159/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
160/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/weights ( type:  Const )
161/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/weights/read ( type:  Identity )
162/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
163/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
164/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
165/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
166/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
167/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
168/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
169/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/depthwise_weights ( type:  Const )
170/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
171/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
172/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
173/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
174/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
175/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
176/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
177/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
178/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/weights ( type:  Const )
179/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/weights/read ( type:  Identity )
180/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
181/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
182/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
183/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
184/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
185/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
186/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
187/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/weights ( type:  Const )
188/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/weights/read ( type:  Identity )
189/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
190/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
191/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
192/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
193/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
194/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
195/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
196/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/depthwise_weights ( type:  Const )
197/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
198/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
199/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
200/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
201/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
202/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
203/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
204/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
205/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/weights ( type:  Const )
206/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/weights/read ( type:  Identity )
207/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
208/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
209/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
210/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
211/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
212/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
213/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
214/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/weights ( type:  Const )
215/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/weights/read ( type:  Identity )
216/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
217/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
218/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
219/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
220/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
221/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
222/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
223/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/depthwise_weights ( type:  Const )
224/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
225/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
226/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
227/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
228/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
229/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
230/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
231/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
232/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/weights ( type:  Const )
233/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/weights/read ( type:  Identity )
234/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
235/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
236/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
237/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
238/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
239/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
240/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
241/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/weights ( type:  Const )
242/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/weights/read ( type:  Identity )
243/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
244/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
245/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
246/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
247/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
248/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
249/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
250/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/depthwise_weights ( type:  Const )
251/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
252/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
253/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
254/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
255/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
256/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
257/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
258/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
259/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/weights ( type:  Const )
260/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/weights/read ( type:  Identity )
261/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
262/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
263/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
264/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
265/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
266/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
267/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
268/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/weights ( type:  Const )
269/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/weights/read ( type:  Identity )
270/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
271/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
272/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
273/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
274/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
275/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
276/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
277/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/depthwise_weights ( type:  Const )
278/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
279/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
280/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
281/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
282/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
283/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
284/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
285/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
286/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/weights ( type:  Const )
287/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/weights/read ( type:  Identity )
288/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
289/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
290/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
291/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
292/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
293/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
294/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
295/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/weights ( type:  Const )
296/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/weights/read ( type:  Identity )
297/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
298/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
299/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
300/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
301/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
302/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
303/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
304/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/depthwise_weights ( type:  Const )
305/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
306/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
307/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
308/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
309/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
310/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
311/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
312/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
313/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/weights ( type:  Const )
314/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/weights/read ( type:  Identity )
315/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
316/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
317/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
318/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
319/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
320/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
321/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
322/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/weights ( type:  Const )
323/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/weights/read ( type:  Identity )
324/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
325/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
326/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
327/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
328/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
329/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
330/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
331/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/depthwise_weights ( type:  Const )
332/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
333/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
334/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
335/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
336/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
337/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
338/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
339/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
340/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/weights ( type:  Const )
341/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/weights/read ( type:  Identity )
342/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
343/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
344/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
345/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
346/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
347/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
348/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
349/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/weights ( type:  Const )
350/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/weights/read ( type:  Identity )
351/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
352/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
353/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
354/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
355/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
356/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
357/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
358/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/depthwise_weights ( type:  Const )
359/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
360/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
361/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
362/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
363/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
364/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
365/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
366/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
367/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/weights ( type:  Const )
368/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/weights/read ( type:  Identity )
369/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/moving_variance ( type:  Const )
370/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/moving_variance/read ( type:  Identity )
371/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/moving_mean ( type:  Const )
372/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/moving_mean/read ( type:  Identity )
373/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/Const ( type:  Const )
374/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/beta ( type:  Const )
375/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/beta/read ( type:  Identity )
376/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/weights ( type:  Const )
377/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/weights/read ( type:  Identity )
378/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/moving_variance ( type:  Const )
379/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/moving_variance/read ( type:  Identity )
380/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/moving_mean ( type:  Const )
381/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/moving_mean/read ( type:  Identity )
382/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/Const ( type:  Const )
383/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/beta ( type:  Const )
384/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/beta/read ( type:  Identity )
385/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/depthwise_weights ( type:  Const )
386/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/depthwise_weights/read ( type:  Identity )
387/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/moving_variance ( type:  Const )
388/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/moving_variance/read ( type:  Identity )
389/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/moving_mean ( type:  Const )
390/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/moving_mean/read ( type:  Identity )
391/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/Const ( type:  Const )
392/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/beta ( type:  Const )
393/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/beta/read ( type:  Identity )
394/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/weights ( type:  Const )
395/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/weights/read ( type:  Identity )
396/563: Analysing op name: pfld_inference/conv2/dwise/BatchNorm/moving_variance ( type:  Const )
397/563: Analysing op name: pfld_inference/conv2/dwise/BatchNorm/moving_variance/read ( type:  Identity )
398/563: Analysing op name: pfld_inference/conv2/dwise/BatchNorm/moving_mean ( type:  Const )
399/563: Analysing op name: pfld_inference/conv2/dwise/BatchNorm/moving_mean/read ( type:  Identity )
400/563: Analysing op name: pfld_inference/conv2/dwise/BatchNorm/Const ( type:  Const )
401/563: Analysing op name: pfld_inference/conv2/dwise/BatchNorm/beta ( type:  Const )
402/563: Analysing op name: pfld_inference/conv2/dwise/BatchNorm/beta/read ( type:  Identity )
403/563: Analysing op name: pfld_inference/conv2/dwise/pointwise_weights ( type:  Const )
404/563: Analysing op name: pfld_inference/conv2/dwise/pointwise_weights/read ( type:  Identity )
405/563: Analysing op name: pfld_inference/conv2/dwise/depthwise_weights ( type:  Const )
406/563: Analysing op name: pfld_inference/conv2/dwise/depthwise_weights/read ( type:  Identity )
407/563: Analysing op name: pfld_inference/conv1/BatchNorm/moving_variance ( type:  Const )
408/563: Analysing op name: pfld_inference/conv1/BatchNorm/moving_variance/read ( type:  Identity )
409/563: Analysing op name: pfld_inference/conv1/BatchNorm/moving_mean ( type:  Const )
410/563: Analysing op name: pfld_inference/conv1/BatchNorm/moving_mean/read ( type:  Identity )
411/563: Analysing op name: pfld_inference/conv1/BatchNorm/Const ( type:  Const )
412/563: Analysing op name: pfld_inference/conv1/BatchNorm/beta ( type:  Const )
413/563: Analysing op name: pfld_inference/conv1/BatchNorm/beta/read ( type:  Identity )
414/563: Analysing op name: pfld_inference/conv1/weights ( type:  Const )
415/563: Analysing op name: pfld_inference/conv1/weights/read ( type:  Identity )
416/563: Analysing op name: image_batch ( type:  Placeholder )
Skipping name of placeholder
417/563: Analysing op name: pfld_inference/conv1/Conv2D ( type:  Conv2D )
418/563: Analysing op name: pfld_inference/conv1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
419/563: Analysing op name: pfld_inference/conv1/Relu6 ( type:  Relu6 )
420/563: Analysing op name: pfld_inference/conv2/dwise/separable_conv2d/depthwise ( type:  DepthwiseConv2dNative )
421/563: Analysing op name: pfld_inference/conv2/dwise/separable_conv2d ( type:  Conv2D )
422/563: Analysing op name: pfld_inference/conv2/dwise/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
423/563: Analysing op name: pfld_inference/conv2/dwise/Relu6 ( type:  Relu6 )
424/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
425/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
426/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
427/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
428/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
429/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
430/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
431/563: Analysing op name: pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
432/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
433/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
434/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
435/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
436/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
437/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
438/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
439/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
440/563: Analysing op name: pfld_inference/conv3_2/inbottleneck/add ( type:  Add )
441/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
442/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
443/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
444/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
445/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
446/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
447/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
448/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
449/563: Analysing op name: pfld_inference/conv3_3/inbottleneck/add ( type:  Add )
450/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
451/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
452/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
453/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
454/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
455/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
456/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
457/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
458/563: Analysing op name: pfld_inference/conv3_4/inbottleneck/add ( type:  Add )
459/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
460/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
461/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
462/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
463/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
464/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
465/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
466/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
467/563: Analysing op name: pfld_inference/conv3_5/inbottleneck/add ( type:  Add )
468/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
469/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
470/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
471/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
472/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
473/563: Analysing op name: pfld_inference/conv4/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
474/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
475/563: Analysing op name: pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
476/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
477/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
478/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
479/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
480/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
481/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
482/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
483/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
484/563: Analysing op name: pfld_inference/conv5_1/inbottleneck/add ( type:  Add )
485/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
486/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
487/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
488/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
489/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
490/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
491/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
492/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
493/563: Analysing op name: pfld_inference/conv5_2/inbottleneck/add ( type:  Add )
494/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
495/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
496/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
497/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
498/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
499/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
500/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
501/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
502/563: Analysing op name: pfld_inference/conv5_3/inbottleneck/add ( type:  Add )
503/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
504/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
505/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
506/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
507/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
508/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
509/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
510/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
511/563: Analysing op name: pfld_inference/conv5_4/inbottleneck/add ( type:  Add )
512/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
513/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
514/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
515/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
516/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
517/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
518/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
519/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
520/563: Analysing op name: pfld_inference/conv5_5/inbottleneck/add ( type:  Add )
521/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
522/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
523/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
524/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
525/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
526/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
527/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
528/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
529/563: Analysing op name: pfld_inference/conv5_6/inbottleneck/add ( type:  Add )
530/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/Conv2D ( type:  Conv2D )
531/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_3/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
532/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/Conv2D ( type:  Conv2D )
533/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
534/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_1/Relu6 ( type:  Relu6 )
535/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/depthwise ( type:  DepthwiseConv2dNative )
536/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
537/563: Analysing op name: pfld_inference/conv6/inbottleneck/separable2d/Relu6 ( type:  Relu6 )
538/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/Conv2D ( type:  Conv2D )
539/563: Analysing op name: pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
540/563: Analysing op name: pfld_inference/conv6/inbottleneck/add ( type:  Add )
541/563: Analysing op name: pfld_inference/AvgPool2D/AvgPool ( type:  AvgPool )
542/563: Analysing op name: pfld_inference/Flatten/flatten/Shape ( type:  Shape )
543/563: Analysing op name: pfld_inference/Flatten/flatten/strided_slice ( type:  StridedSlice )
544/563: Analysing op name: pfld_inference/Flatten/flatten/Reshape/shape ( type:  Pack )
545/563: Analysing op name: pfld_inference/Flatten/flatten/Reshape ( type:  Reshape )
546/563: Analysing op name: pfld_inference/conv7/Conv2D ( type:  Conv2D )
547/563: Analysing op name: pfld_inference/conv7/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
548/563: Analysing op name: pfld_inference/conv7/Relu6 ( type:  Relu6 )
549/563: Analysing op name: pfld_inference/AvgPool2D_1/AvgPool ( type:  AvgPool )
550/563: Analysing op name: pfld_inference/Flatten_1/flatten/Shape ( type:  Shape )
551/563: Analysing op name: pfld_inference/Flatten_1/flatten/strided_slice ( type:  StridedSlice )
552/563: Analysing op name: pfld_inference/Flatten_1/flatten/Reshape/shape ( type:  Pack )
553/563: Analysing op name: pfld_inference/Flatten_1/flatten/Reshape ( type:  Reshape )
554/563: Analysing op name: pfld_inference/conv8/Conv2D ( type:  Conv2D )
555/563: Analysing op name: pfld_inference/conv8/BatchNorm/FusedBatchNorm ( type:  FusedBatchNorm )
556/563: Analysing op name: pfld_inference/conv8/Relu6 ( type:  Relu6 )
557/563: Analysing op name: pfld_inference/Flatten_2/flatten/Shape ( type:  Shape )
558/563: Analysing op name: pfld_inference/Flatten_2/flatten/strided_slice ( type:  StridedSlice )
559/563: Analysing op name: pfld_inference/Flatten_2/flatten/Reshape/shape ( type:  Pack )
560/563: Analysing op name: pfld_inference/Flatten_2/flatten/Reshape ( type:  Reshape )
561/563: Analysing op name: pfld_inference/concat ( type:  ConcatV2 )
562/563: Analysing op name: pfld_inference/fc/MatMul ( type:  MatMul )
563/563: Analysing op name: pfld_inference/fc/BiasAdd ( type:  BiasAdd )
Translation to CoreML spec completed. Now compiling and saving the CoreML model.

 Core ML model generated. Saved at location: models2/save_models/68/new_dm075_im84_WFLW68/pfld.mlmodel 

Core ML input(s): 
 [name: "image_batch__0"
type {
  multiArrayType {
    shape: 3
    shape: 84
    shape: 84
    dataType: DOUBLE
  }
}
]
Core ML output(s): 
 [name: "pfld_inference__fc__BiasAdd__0"
type {
  multiArrayType {
    shape: 136
    dataType: DOUBLE
  }
}
]
]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# sh run.sh savevim save_model.py [4Psh run.sh save[Kvim test_model.py 
[?2004h[?1049h[22;0;0t[?1h=[?2004h[1;13r[?12h[?12l[27m[23m[29m[m[H[2J[?25l[13;1H"test_model.py" 230L, 9716C[2;1H▽[6n[2;1H  [1;1H[>c]10;?]11;?[1;21Hannotate_pre_landmark = pre_landmark.reshape(-[31m1[m, [31m2[m) * [h, w][2;21H[38;5;130mfor[m land_id, (x, y) [38;5;130min[m [36menumerate[m(annotate_pre_landmark.astype(np.int32)):[3;25Hcv2.circle(img, (x, y), [31m1[m, ([31m0[m, [31m255[m, [31m0[m), [31m1[m)[4;25Hcv2.imwrite([31m"./show_labeled"[m + [36mstr[m(land_id) + [31m".jpg"[m, img)[5;21Himg = image.copy()[6;21Hannotate_landmark = landmarks[file_id].reshape(-[31m1[m, [31m2[m) * [h, w][7;21H[38;5;130mfor[m land_id, (x, y) [38;5;130min[m [36menumerate[m(annotate_landmark.astype(np.int32)):[8;25Hcv2.circle(img, (x, y), [31m1[m, ([31m0[m, [31m255[m, [31m0[m), [31m1[m)[9;25Hcv2.imwrite([31m"./show_test"[m + [36mstr[m(land_id) + [31m".jpg"[m, img)[10;21H[38;5;130mbreak[m[11;21H[36mprint[m(os.path.join(args.out_dir, filename))[12;21Hcv2.imwrite(os.path.join(args.out_dir, filename), image)[13;84H122,17[8C53%[6;17H[?25h[?12$p[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;21Himg = image.copy()[13;1H[K[13;84H121,17[8C52%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;17H[38;5;130mif[m DEBUG:[13;84H[K[13;84H120,17[8C52%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hh, w, _ = image.shape[13;84H[K[13;84H119,17[8C51%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;17H[34m# save labeled image[m[13;84H[K[13;84H118,17[8C51%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hpre_landmark = pre_landmarks[[31m0[m][13;84H[K[13;84H117,17[8C50%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[36mprint[m([31m"elaps: "[m, time.time() - st)[13;84H[K[13;84H116,17[8C50%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[34m# print(pre_landmarks)[m[13;84H[K[13;84H115,17[8C50%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hpre_landmarks = inf_sess.run(landmarks_pre, feed_dict=feed_dict)[13;84H[K[13;84H114,17[8C49%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hst = time.time()[13;84H[K[13;84H113,17[8C49%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H}[13;84H[K[13;84H112,17[8C48%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;21Himage_batch: [36minput[m[13;84H[K[13;84H111,17[8C48%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hfeed_dict = {[13;84H[K[13;84H110,17[8C47%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H109,17[8C47%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;17H[34m# print(input.shape)[m[13;84H[K[13;84H108,17[8C46%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[36minput[m = np.expand_dims([36minput[m, [31m0[m)[4;29H[106m{[6;17H}[m[13;84H[K[13;84H107,17[8C46%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[36minput[m = [36minput[m.astype(np.float32) / [31m256.0[m[5;29H{[7;17H}[13;84H[K[13;84H106,17[8C45%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[36minput[m = cv2.resize([36minput[m, (args.image_size, args.image_size))[13;84H[K[13;84H105,17[8C45%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17H[36minput[m = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)[13;84H[K[13;84H104,0-1[7C44%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;17H[34m# image = cv2.resize(image, (image_size, image_size))[m[13;84H[K[13;84H103,17[8C44%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Himage = cv2.imread([36mfile[m)[13;84H[K[13;84H102,17[8C44%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hfilename = os.path.split([36mfile[m)[-[31m1[m][13;84H[K[13;84H101,17[8C43%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[38;5;130mfor[m file_id, [36mfile[m [38;5;130min[m [36menumerate[m(file_list):[13;84H[K[13;84H100,17[8C43%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m(file_list)[13;84H[K[13;84H99,17[9C42%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;17Hargs.test_list, args.num_labels)[13;84H[K[13;84H98,17[9C42%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Hfile_list, landmarks, attributes, euler_angles = dataloader.gen_data([13;84H[K[13;84H97,17[9C41%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Hdataloader = DataLoader(args.test_list, args, [31m"test"[m)[13;84H[K[13;84H96,17[9C41%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H95,17[9C40%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Hsaver.restore(inf_sess, model_path)[13;84H[K[13;84H94,17[9C40%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m'Checkpoint file: {}'[m.format(model_path))[13;84H[K[13;84H93,17[9C39%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hmodel_path[model_path.find([31m'model.ckpt-'[m) + [31m11[m:]) + [31m1[m[13;84H[K[13;84H92,17[9C39%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Hepoch_start = [36mint[m([13;84H[K[13;84H91,17[9C38%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[38;5;130massert[m (ckpt [38;5;130mand[m model_path)[13;84H[K[13;84H90,0-1[8C38%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Hmodel_path = ckpt.model_checkpoint_path[13;84H[K[13;84H89,17[9C38%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m'ckpt: {}'[m.format(ckpt))[13;84H[K[13;84H88,17[9C37%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;13Hckpt = tf.train.get_checkpoint_state(args.pretrained_model)[13;84H[K[13;84H87,17[9C37%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m'Model directory: {}'[m.format(args.pretrained_model))[13;84H[K[13;84H86,17[9C36%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[38;5;130mwith[m inf_sess.as_default():[13;84H[K[13;84H85,17[9C36%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H84,17[9C35%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hinf_sess.run(tf.local_variables_initializer())[13;84H[K[13;84H83,17[9C35%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hinf_sess.run(tf.global_variables_initializer())[13;84H[K[13;84H82,17[9C34%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hlog_device_placement=[36mFalse[m))[13;84H[K[13;84H81,17[9C34%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hallow_soft_placement=[36mFalse[m,[13;84H[K[13;84H80,17[9C33%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;17Hgpu_options=gpu_options,[13;84H[K[13;84H79,0-1[8C33%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;13Hconfig=tf.ConfigProto([13;84H[K[13;84H78,17[9C33%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Hgraph=inf_g,[13;84H[K[13;84H77,17[9C32%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hinf_sess = tf.Session([13;84H[K[13;84H76,17[9C32%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hgpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=[31m1.0[m)[13;84H[K[13;84H75,17[9C31%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H74,17[9C31%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m"no quantize, so float: "[m, args.num_quant)[13;84H[K[13;84H73,17[9C30%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[38;5;130melse[m:[13;84H[K[13;84H72,17[9C30%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13Htf.contrib.quantize.create_eval_graph(input_graph=inf_g)[13;84H[K[13;84H71,17[9C29%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[34m# ref: https://github.com/tensorflow/tensorflow/tree/r1.14/tensorflow/contrib/quantize[m[13;84H[K[13;84H70,17[9C29%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m            """[m[13;84H[K[13;84H69,0-1[8C28%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;1H[31m            )[m[13;84H[K[13;84H68,17[9C28%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                scope=None[m[13;84H[K[13;84H67,13[9C27%[6;13H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                quant_delay=None,[m[13;84H[K[13;84H66,17[9C27%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                symmetric=False,[m[13;84H[K[13;84H65,17[9C27%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                activation_bits=args.num_quant,[m[13;84H[K[13;84H64,15[9C26%[6;15H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                weight_bits=args.num_quant,[m[13;84H[K[13;84H63,13[9C26%[6;13H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m                input_graph=inf_g,[m[13;84H[K[13;84H62,17[9C25%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[31m            tf.contrib.quantize.experimental_create_eval_graph([m[13;84H[K[13;84H61,17[9C25%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;13H[31m"""[m[13;84H[K[13;84H60,17[9C24%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m"quantize by: "[m, args.num_quant)[13;84H[K[13;84H59,17[9C24%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mprint[m([31m"====================================="[m)[13;84H[K[13;84H58,17[9C23%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[38;5;130mif[m args.num_quant < [31m64[m:[13;84H[K[13;84H57,17[9C23%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9H[34m# quantize[m[13;84H[K[13;84H56,17[9C22%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hsaver = tf.train.Saver(save_params, max_to_keep=[36mNone[m)[13;84H[K[13;84H55,15[9C22%[6;15H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hsave_params = tf.trainable_variables()[13;84H[K[13;84H54,17[9C22%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H53,17[9C21%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;13Himage_batch, landmark_batch, phase_train_placeholder, args)[13;84H[K[13;84H52,17[9C21%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlandmarks_pre, _, _ = create_model([13;84H[K[13;84H51,17[9C20%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hphase_train_placeholder = tf.constant([36mFalse[m, name=[31m'phase_train'[m)[13;84H[K[13;84H50,17[9C20%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H49,17[9C19%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;13H[36mNone[m, args.num_labels * [31m2[m), name=[31m'landmark_batch'[m)[13;84H[K[13;84H48,0-1[8C19%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hlandmark_batch = tf.placeholder(tf.float32, shape=([13;84H[K[13;84H47,17[9C18%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;38Hname=[31m'image_batch'[m)[13;84H[K[13;84H46,17[9C18%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Himage_batch = tf.placeholder(tf.float32, shape=([36mNone[m, args.image_size, args.image_size, [31m3[m),[13;84H[K[13;84H45,17[9C17%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;1H[1;12r[1;1H[L[1;13r[1;5H[38;5;130mwith[m tf.Graph().as_default() [38;5;130mas[m inf_g:[13;84H[K[13;84H44,0-1[8C17%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H43,17[9C16%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5Hlandmark_01_num = [31m0[m[13;84H[K[13;84H42,17[9C16%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5Hlandmark_error = [31m0[m[13;84H[K[13;84H41,17[9C16%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5HNRMSE = [31m0[m[13;84H[K[13;84H40,17[9C15%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5Hloss_sum = [31m0[m[13;84H[K[13;84H39,17[9C15%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H38,0-1[8C14%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[13;84H[K[13;84H37,17[9C14%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hos.mkdir(args.out_dir)[13;84H[K[13;84H36,17[9C13%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hshutil.rmtree(args.out_dir)[13;84H[K[13;84H35,13[9C13%[6;13H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5H[38;5;130melse[m:[13;84H[K[13;84H34,16[9C12%[6;16H[?25h[?25l[1;12r[1;1H[L[1;13r[1;9Hos.mkdir(args.out_dir)[13;84H[K[13;84H33,0-1[8C12%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5H[38;5;130mif[m [38;5;130mnot[m os.path.exists(args.out_dir):[13;84H[K[13;84H32,0-1[8C11%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;5H[36mprint[m([31m"args: "[m, args)[6;17H[106m([12C)[m[13;84H[K[13;84H31,17[9C11%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;1H[38;5;130mdef[m [36mmain[m(args):[7;17H([12C)[13;84H[K[13;84H30,17[9C11%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H29,9[10C10%[6;9H[?25h[?25l[1;12r[1;1H[L[1;13r[6;17H[106m([12C)[m[13;84H[K[13;84H28,17[9C10%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1HDEBUG = [36mFalse[m[7;17H([12C)[13;84H[K[13;84H27,17[10C9%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H26,17[10C9%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H25,15[10C8%[6;15H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m os[13;84H[K[13;84H24,0-1[9C8%[6;1H[?25h[?25l[13;74H~@k[6;1H[13;74H   [6;1H[1;12r[1;1H[L[1;13r[1;1H[35mimport[m sys[13;84H[K[13;84H23,0-1[9C7%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m argparse[13;84H[K[13;84H22,13[10C7%[6;13H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m time[13;84H[K[13;84H21,0-1[9C6%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m shutil[13;84H[K[13;84H20,0-1[9C6%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m cv2[13;84H[K[13;84H19,9[11C5%[6;9H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m numpy [38;5;130mas[m np[13;84H[K[13;84H18,10[10C5%[6;10H[?25h[?25l[13;74H~@k[6;10H[13;74H   [6;15H[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m tensorflow.python.framework [35mimport[m graph_util[13;84H[K[13;84H17,15[10C5%[6;15H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mimport[m tensorflow [38;5;130mas[m tf[13;84H[K[13;84H16,11[10C4%[6;11H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[34m# print('pid: {}     GPU: {}'.format(os.getpid(), os.environ['CUDA_VISIBLE_DEVICES']))[m[13;84H[K[13;84H15,13[10C4%[6;13H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[34m# os.environ['CUDA_VISIBLE_DEVICES'] = '0'[m[13;84H[K[13;84H14,10[10C3%[6;10H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H13,17[10C3%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H12,17[10C2%[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [6;17H[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m generate_data [35mimport[m DataLoader[13;84H[K[13;84H11,17[10C2%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m pfld [35mimport[m create_model[13;84H[K[13;84H10,17[10C1%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[13;84H[K[13;84H9,17[11C1%[6;17H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m __future__ [35mimport[m print_function[13;84H[K[13;84H8,0-1[10C0%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m __future__ [35mimport[m division[13;84H[K[13;84H7,0-1[10C0%[6;1H[?25h[?25l[1;12r[1;1H[L[1;13r[1;1H[35mfrom[m __future__ [35mimport[m absolute_import[13;84H[K[13;84H6,17[10CTop[6;17H[?25h[?25l[13;74H~@k[6;17H[13;74H   [5;17H[13;84H5[5;17H[?25h[?25l[13;84H4,0-1[4;1H[?25h[?25l[13;84H3,17 [3;17H[?25h[?25l[13;84H2[2;17H[?25h[?25l[13;84H1[1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [1;17H[?25h[?25l[13;74H~@k[1;17H[13;74H   [2;17H[13;84H2[2;17H[?25h[?25l[13;74H~@k[2;17H[13;74H   [3;17H[13;84H3[3;17H[?25h[?25l[13;74H~@k[3;17H[13;74H   [4;1H[13;84H4,0-1[4;1H[?25h[?25l[13;74H~@k[4;1H[13;74H   [5;17H[13;84H5,17 [5;17H[?25h[?25l[13;74Hi[5;17H[13;74H [5;17H[13;1H[1m-- INSERT --[m[13;84H[K[13;84H5,17[10CTop[5;17H[?25h[?25l[13;87H6[5;16H[?25h[?25l[13;87H5[5;15H[?25h[?25l[13;87H4[5;14H[?25h[?25l[13;87H3[5;13H[?25h[?25l[13;87H2[5;12H[?25h[?25l[13;87H1[5;11H[?25h[?25l[13;87H0[5;10H[?25h[?25l_ [35mimport[m create_model[13;87H1[5;11H[?25h[?25ln [35mimport[m create_model[13;87H2[5;12H[?25h[?25le [35mimport[m create_model[13;87H3[5;13H[?25h[?25lw [35mimport[m create_model[13;87H4[5;14H[?25h[13;1H[K[5;13H[?25l[13;74H^[[5;13H[13;74H  [5;14H[13;84H5,13[10CTop[5;13H[?25h[?25l[13;74H:[5;13H[13;74H[K[13;1H:[?2004h[?25hw[?25l[?25hq[?25l[?25h[?25l[?2004l"test_model.py" 230L, 9720C written
[?2004l[?1l>[?25h[?1049l[23;0;0t]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# sh run.sh test
run test
['test_model.py', '--pretrained_model=models2/save_models/68/new_dm075_im84_WFLW68', '--test_list=data/test_moru_dataset/list.txt', '--num_labels=68', '--learning_rate=0.0001', '--level=L1', '--image_size=84', '--batch_size=128', '--depth_multi=0.75', '--out_dir=sample_new_dm075_im84_WFLW68', '--num_quant=64', '--is_augment=False']
args:  Namespace(batch_size=128, depth_multi=0.75, image_channels=3, image_size=84, is_augment=False, learning_rate=0.0001, level='L1', lr_epoch='10,20,30,40,200,500', max_epoch=1000, num_labels=68, num_quant=64, out_dir='sample_new_dm075_im84_WFLW68', pretrained_model='models2/save_models/68/new_dm075_im84_WFLW68', save_image_example=True, seed=666, test_list='data/test_moru_dataset/list.txt', weight_decay=5e-05)
WARNING: Logging before flag parsing goes to stderr.
W0207 06:18:08.793783 139681318696768 deprecation_wrapper.py:119] From test_model.py:40: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0207 06:18:08.796255 139681318696768 deprecation_wrapper.py:119] From /usr/src/app/pfld_new.py:176: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

labels;  68
labels;  68
W0207 06:18:14.802861 139681318696768 deprecation_wrapper.py:119] From /usr/src/app/pfld_new.py:75: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

PFLD input shape(image_batch:0): (?, 84, 84, 3)
pfld_inference/conv1/Relu6:0 (?, 42, 42, 64)
W0207 06:18:15.011479 139681318696768 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
pfld_inference/conv2/dwise/Relu6:0 (?, 42, 42, 48)
pfld_inference/conv3_1/inbottleneck/conv2d_1/Relu6:0 (?, 42, 42, 96)
pfld_inference/conv3_1/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_1/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_2/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_2/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_2/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_2/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_3/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_3/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_3/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_3/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_4/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_4/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_4/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv3_5/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_5/inbottleneck/separable2d/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv3_5/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 21, 21, 48)
pfld_inference/conv3_5/inbottleneck/add:0 (?, 21, 21, 48)
pfld_inference/conv4/inbottleneck/conv2d_1/Relu6:0 (?, 21, 21, 96)
pfld_inference/conv4/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 96)
pfld_inference/conv4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_1/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_1/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_1/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_1/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_2/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_2/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_2/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_2/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_3/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_3/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_3/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_3/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_4/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_4/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_4/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_4/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_5/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_5/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_5/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_5/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv5_6/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_6/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 384)
pfld_inference/conv5_6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 96)
pfld_inference/conv5_6/inbottleneck/add:0 (?, 11, 11, 96)
pfld_inference/conv6/inbottleneck/conv2d_1/Relu6:0 (?, 11, 11, 192)
pfld_inference/conv6/inbottleneck/separable2d/Relu6:0 (?, 11, 11, 192)
pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 12)
pfld_inference/conv6/inbottleneck/conv2d_2/BatchNorm/FusedBatchNorm:0 (?, 11, 11, 12)
pfld_inference/conv6/inbottleneck/add:0 (?, 11, 11, 12)
pfld_inference/conv7/Relu6:0 (?, 6, 6, 32)
pfld_inference/conv8/Relu6:0 (?, 2, 2, 48)
pfld_inference/AvgPool2D/AvgPool:0 (?, 1, 1, 12)
pfld_inference/AvgPool2D_1/AvgPool:0 (?, 1, 1, 32)
W0207 06:18:16.494892 139681318696768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
last layer name
pfld_inference/fc/BiasAdd:0 (?, 136)

auxiliary net
pfld_conv1/Relu:0 (?, 11, 11, 128)
pfld_conv2/Relu:0 (?, 11, 11, 128)
pfld_conv3/Relu:0 (?, 6, 6, 32)
pfld_conv4/Relu:0 (?, 6, 6, 128)
pool1/MaxPool:0 (?, 6, 6, 128)
Flatten/flatten/Reshape:0 (?, 4608)
pfld_fc1/BatchNorm/Reshape_1:0 (?, 32)
pfld_fc2/BatchNorm/Reshape_1:0 (?, 3)
==========finish define graph===========
W0207 06:18:17.126175 139681318696768 deprecation_wrapper.py:119] From test_model.py:49: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0207 06:18:17.126410 139681318696768 deprecation_wrapper.py:119] From test_model.py:50: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

no quantize, so float:  64
W0207 06:18:17.304636 139681318696768 deprecation_wrapper.py:119] From test_model.py:70: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.

2020-02-07 06:18:17.304973: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-07 06:18:17.312870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-02-07 06:18:19.958840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:18:19.959756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b708d0 executing computations on platform CUDA. Devices:
2020-02-07 06:18:19.959804: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2020-02-07 06:18:19.981398: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300050000 Hz
2020-02-07 06:18:19.981875: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5f817c0 executing computations on platform Host. Devices:
2020-02-07 06:18:19.981945: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-07 06:18:19.982221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:18:19.983018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
2020-02-07 06:18:19.983374: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:18:19.984950: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:18:19.986317: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-07 06:18:19.986709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-07 06:18:19.988600: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-07 06:18:19.989966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-07 06:18:19.993739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-07 06:18:19.993880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:18:19.994736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:18:19.995498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-02-07 06:18:19.995567: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-07 06:18:19.997209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-07 06:18:19.997235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-07 06:18:19.997249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-02-07 06:18:19.997407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:18:19.998240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-07 06:18:19.999006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2020-02-07 06:18:20.446587: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 11.17G (11996954624 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
Model directory: models2/save_models/68/new_dm075_im84_WFLW68
ckpt: model_checkpoint_path: "models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt-89"
all_model_checkpoint_paths: "models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt-89"

Checkpoint file: models2/save_models/68/new_dm075_im84_WFLW68/model.ckpt-89
W0207 06:18:21.132720 139681318696768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
labels;  68
['/usr/src/app/data/test_moru_dataset/imgs/0_IMG_7804_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/1_IMG_7804_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/2_IMG_7805_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/3_IMG_7805_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/4_IMG_7806_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/5_IMG_7807_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/6_IMG_7809_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/7_IMG_7810_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/8_IMG_7816_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/9_IMG_7824_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/10_IMG_7825_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/11_IMG_7826_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/12_IMG_7827_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/13_IMG_7828_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/14_IMG_7829_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/15_IMG_7830_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/16_IMG_7830_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/17_IMG_7831_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/18_IMG_7832_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/19_IMG_7832_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/20_IMG_7833_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/21_IMG_7833_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/22_IMG_7898_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/23_IMG_7903_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/24_IMG_7904_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/25_IMG_7905_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/26_IMG_7909_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/27_IMG_7910_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/28_IMG_7911_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/29_IMG_7912_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/30_IMG_7912_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/31_IMG_7915_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/32_IMG_7915_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/33_IMG_7916_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/34_IMG_7917_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/35_IMG_7917_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/36_IMG_7918_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/37_IMG_7918_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/38_IMG_7923_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/39_IMG_7923_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/40_IMG_7924_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/41_IMG_7925_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/42_IMG_7926_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/43_IMG_7927_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/44_IMG_7927_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/45_IMG_7928_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/46_IMG_7929_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/47_IMG_7929_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/48_IMG_7930_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/49_IMG_7930_1_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/50_IMG_7932_0_0.png'
 '/usr/src/app/data/test_moru_dataset/imgs/51_IMG_7932_1_0.png']
2020-02-07 06:18:24.687013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-07 06:18:24.835649: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
elaps:  0.932037353515625
sample_new_dm075_im84_WFLW68/0_IMG_7804_0_0.png
RMSE:  0.03264572
error_norm:  2.2483324030181393
elaps:  0.005880832672119141
sample_new_dm075_im84_WFLW68/1_IMG_7804_1_0.png
RMSE:  0.032475375
error_norm:  2.611054158769548
elaps:  0.005749702453613281
sample_new_dm075_im84_WFLW68/2_IMG_7805_0_0.png
RMSE:  0.02979619
error_norm:  2.1272983895614743
elaps:  0.0057985782623291016
sample_new_dm075_im84_WFLW68/3_IMG_7805_1_0.png
RMSE:  0.033276714
error_norm:  2.581856726319529
elaps:  0.005892038345336914
sample_new_dm075_im84_WFLW68/4_IMG_7806_1_0.png
RMSE:  0.02978567
error_norm:  2.36793387751095
elaps:  0.00592494010925293
sample_new_dm075_im84_WFLW68/5_IMG_7807_1_0.png
RMSE:  0.030941587
error_norm:  2.4124754942022264
elaps:  0.005593538284301758
sample_new_dm075_im84_WFLW68/6_IMG_7809_1_0.png
RMSE:  0.041952226
error_norm:  3.0594362495467067
elaps:  0.00552678108215332
sample_new_dm075_im84_WFLW68/7_IMG_7810_1_0.png
RMSE:  0.039538797
error_norm:  2.6712457628455013
elaps:  0.005753517150878906
sample_new_dm075_im84_WFLW68/8_IMG_7816_1_0.png
RMSE:  0.036188513
error_norm:  2.535962730180472
elaps:  0.005885124206542969
sample_new_dm075_im84_WFLW68/9_IMG_7824_1_0.png
RMSE:  0.026702007
error_norm:  2.1392282019369304
elaps:  0.0056705474853515625
sample_new_dm075_im84_WFLW68/10_IMG_7825_1_0.png
RMSE:  0.02705204
error_norm:  2.1884759792592376
elaps:  0.005680561065673828
sample_new_dm075_im84_WFLW68/11_IMG_7826_0_0.png
RMSE:  0.034159273
error_norm:  2.70420348783955
elaps:  0.005891084671020508
sample_new_dm075_im84_WFLW68/12_IMG_7827_1_0.png
RMSE:  0.030163666
error_norm:  2.452422887319699
elaps:  0.005780935287475586
sample_new_dm075_im84_WFLW68/13_IMG_7828_1_0.png
RMSE:  0.028003806
error_norm:  1.87594637949951
elaps:  0.005797147750854492
sample_new_dm075_im84_WFLW68/14_IMG_7829_1_0.png
RMSE:  0.033054765
error_norm:  2.140505909686908
elaps:  0.00551295280456543
sample_new_dm075_im84_WFLW68/15_IMG_7830_0_0.png
RMSE:  0.027051348
error_norm:  1.8261375047732145
elaps:  0.005639314651489258
sample_new_dm075_im84_WFLW68/16_IMG_7830_1_0.png
RMSE:  0.033619482
error_norm:  2.3219304097583517
elaps:  0.0054285526275634766
sample_new_dm075_im84_WFLW68/17_IMG_7831_1_0.png
RMSE:  0.032629065
error_norm:  2.2610878963023424
elaps:  0.005898237228393555
sample_new_dm075_im84_WFLW68/18_IMG_7832_0_0.png
RMSE:  0.02720497
error_norm:  2.1350557962432504
elaps:  0.005890846252441406
sample_new_dm075_im84_WFLW68/19_IMG_7832_1_0.png
RMSE:  0.027206741
error_norm:  1.8597351507050917
elaps:  0.00585174560546875
sample_new_dm075_im84_WFLW68/20_IMG_7833_0_0.png
RMSE:  0.02119682
error_norm:  1.7416415624320507
elaps:  0.00565791130065918
sample_new_dm075_im84_WFLW68/21_IMG_7833_1_0.png
RMSE:  0.029568335
error_norm:  2.1971700778231025
elaps:  0.005560874938964844
sample_new_dm075_im84_WFLW68/22_IMG_7898_0_0.png
RMSE:  0.024637865
error_norm:  1.897230489877984
elaps:  0.00560450553894043
sample_new_dm075_im84_WFLW68/23_IMG_7903_0_0.png
RMSE:  0.02979813
error_norm:  2.094631952466443
elaps:  0.0058689117431640625
sample_new_dm075_im84_WFLW68/24_IMG_7904_0_0.png
RMSE:  0.029495148
error_norm:  2.131430112523958
elaps:  0.005860567092895508
sample_new_dm075_im84_WFLW68/25_IMG_7905_0_0.png
RMSE:  0.02676156
error_norm:  2.0401413158979267
elaps:  0.0055272579193115234
sample_new_dm075_im84_WFLW68/26_IMG_7909_1_0.png
RMSE:  0.029271998
error_norm:  2.2924674379173666
elaps:  0.005501985549926758
sample_new_dm075_im84_WFLW68/27_IMG_7910_1_0.png
RMSE:  0.030878412
error_norm:  2.2567810430191457
elaps:  0.00577092170715332
sample_new_dm075_im84_WFLW68/28_IMG_7911_0_0.png
RMSE:  0.031995006
error_norm:  2.302093286474701
elaps:  0.0054090023040771484
sample_new_dm075_im84_WFLW68/29_IMG_7912_0_0.png
RMSE:  0.033463564
error_norm:  2.3737192507833242
elaps:  0.005445718765258789
sample_new_dm075_im84_WFLW68/30_IMG_7912_1_0.png
RMSE:  0.026495062
error_norm:  1.8215082134120166
elaps:  0.005759716033935547
sample_new_dm075_im84_WFLW68/31_IMG_7915_0_0.png
RMSE:  0.028860193
error_norm:  1.9897802732884884
elaps:  0.005536079406738281
sample_new_dm075_im84_WFLW68/32_IMG_7915_1_0.png
RMSE:  0.027347226
error_norm:  2.1650221298914403
elaps:  0.005782365798950195
sample_new_dm075_im84_WFLW68/33_IMG_7916_0_0.png
RMSE:  0.033406474
error_norm:  2.1518332127016038
elaps:  0.005940914154052734
sample_new_dm075_im84_WFLW68/34_IMG_7917_0_0.png
RMSE:  0.026993984
error_norm:  1.8515240878332406
elaps:  0.0057032108306884766
sample_new_dm075_im84_WFLW68/35_IMG_7917_1_0.png
RMSE:  0.019887893
error_norm:  1.4859874991816469
elaps:  0.005881309509277344
sample_new_dm075_im84_WFLW68/36_IMG_7918_0_0.png
RMSE:  0.026990553
error_norm:  1.854285521665588
elaps:  0.005652666091918945
sample_new_dm075_im84_WFLW68/37_IMG_7918_1_0.png
RMSE:  0.020793876
error_norm:  1.5321903776493855
elaps:  0.005865812301635742
sample_new_dm075_im84_WFLW68/38_IMG_7923_0_0.png
RMSE:  0.031230193
error_norm:  2.355115864891559
elaps:  0.005619049072265625
sample_new_dm075_im84_WFLW68/39_IMG_7923_1_0.png
RMSE:  0.02984416
error_norm:  2.286091214977205
elaps:  0.005706310272216797
sample_new_dm075_im84_WFLW68/40_IMG_7924_1_0.png
RMSE:  0.027606692
error_norm:  2.1387107288464904
elaps:  0.005513668060302734
sample_new_dm075_im84_WFLW68/41_IMG_7925_1_0.png
RMSE:  0.025751084
error_norm:  2.0229276921600103
elaps:  0.005823850631713867
sample_new_dm075_im84_WFLW68/42_IMG_7926_1_0.png
RMSE:  0.025478676
error_norm:  2.030341476085596
elaps:  0.005737781524658203
sample_new_dm075_im84_WFLW68/43_IMG_7927_0_0.png
RMSE:  0.02874891
error_norm:  2.128063277923502
elaps:  0.005656242370605469
sample_new_dm075_im84_WFLW68/44_IMG_7927_1_0.png
RMSE:  0.03022473
error_norm:  2.394010547082871
elaps:  0.005825519561767578
sample_new_dm075_im84_WFLW68/45_IMG_7928_1_0.png
RMSE:  0.029386204
error_norm:  2.2159832441248
elaps:  0.0054242610931396484
sample_new_dm075_im84_WFLW68/46_IMG_7929_0_0.png
RMSE:  0.02944489
error_norm:  2.349790607346222
elaps:  0.005560398101806641
sample_new_dm075_im84_WFLW68/47_IMG_7929_1_0.png
RMSE:  0.028850485
error_norm:  2.1318040280602872
elaps:  0.005909442901611328
sample_new_dm075_im84_WFLW68/48_IMG_7930_0_0.png
RMSE:  0.028692862
error_norm:  2.3277430832386017
elaps:  0.005797386169433594
sample_new_dm075_im84_WFLW68/49_IMG_7930_1_0.png
RMSE:  0.030228116
error_norm:  2.161575228907168
elaps:  0.005885124206542969
sample_new_dm075_im84_WFLW68/50_IMG_7932_0_0.png
RMSE:  0.025515031
error_norm:  1.9673698260448873
elaps:  0.005812883377075195
sample_new_dm075_im84_WFLW68/51_IMG_7932_1_0.png
RMSE:  0.03266829
error_norm:  2.3950858156895265
Test Loss 0.121
Test NRMSE 0.030
mean error and failure rate
mean error : 2.185
failure rate: L1 1.000

]0;root@9e39d96171e8: /usr/src/approot@9e39d96171e8:/usr/src/app# sh run.sh testvim test_model.py [4Psh run.sh savevim test_model.py [4Psh run.sh savevim save_model.py [4Psh run.sh savevim save_model.py test[C[C[C[C[C[C[C[C[C[C[2Ppfld_new[C[C[C[C[3@train_model[C[C[C[C[3Ppfld_new[C[C[C[C[2Psh run.sh savevim pfld_new.py [3@train_model[C[C[C[C[3Ppfld_new[C[C[C[C[2@test_model[C[C[C[Csave[C[C[C[C[C[C[C[C[C[C[4Psh run.sh savevim test_model.py [4Psh run.sh test[K[10P(reverse-i-search)`':[C[19@d': vim test_model.py[C[8@failed reverse-i-search)`do[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@c[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@k[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@e[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@r[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@ [C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@l[C[C[C[C[C[C[C[C[C[C[C[C[C[C[1@o[C[C[C[C[C[C[C[C[C[C[C[C[C[C^C
